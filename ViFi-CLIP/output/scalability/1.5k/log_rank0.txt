[2025-03-13 14:27:26 ViT-B/16] (main.py 348): INFO working dir: output/scalability/1.5k
[2025-03-13 14:27:26 ViT-B/16] (main.py 352): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  DATASET: humanedit
  INPUT_SIZE: 224
  LABEL_LIST: /home/jovyan/BA/Github/thesis-edit-evaluation/data/humanedit/labels.csv
  NUM_CLASSES: 4534
  NUM_FRAMES: 2
  ROOT: /home/jovyan/BA/Github/HumanEdit/videos
  TRAIN_FILE: /home/jovyan/BA/Github/HumanEdit/train_2.5k.txt
  VAL_FILE: /home/jovyan/BA/Github/HumanEdit/test_20.txt
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  PRETRAINED: None
  RESUME: None
OUTPUT: output/scalability/1.5k
PRINT_FREQ: 50
SAVE_FREQ: 10
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: False
  BATCH_SIZE: 16
  EPOCHS: 11
  LR: 2e-06
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 5
  WEIGHT_DECAY: 0.001
TRAINER:
  ViFi_CLIP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
VAL_FREQ: 1
[2025-03-13 14:27:26 ViT-B/16] (vificlip.py 242): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-13 14:27:28 ViT-B/16] (vificlip.py 245): INFO Building ViFi-CLIP CLIP
[2025-03-13 14:27:28 ViT-B/16] (vificlip.py 262): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-13 14:27:28 ViT-B/16] (vificlip.py 286): INFO Total learnable items: 302
[2025-03-13 14:27:32 ViT-B/16] (main.py 184): INFO Train: [0/11][0/156]	eta 0:08:12 lr 0.000000000	time 3.1602 (3.1602)	tot_loss 4.0588 (4.0588)	mem 6882MB
