[2025-03-03 09:32:46 ViT-B/16] (2516783699.py 19): INFO working dir: exp
[2025-03-03 09:32:55 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:32:57 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:32:57 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:32:57 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:33:45 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form None....................
[2025-03-03 09:34:35 ViT-B/32] (2516783699.py 19): INFO working dir: exp
[2025-03-03 09:34:37 ViT-B/32] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/32)
[2025-03-03 09:34:38 ViT-B/32] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:34:38 ViT-B/32] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:34:38 ViT-B/32] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:34:39 ViT-B/32] (2665388570.py 1): INFO ==============> Resuming form None....................
[2025-03-03 09:35:04 ViT-B/32] (2071167465.py 1): INFO ==============> Resuming form None....................
[2025-03-03 09:35:20 ViT-B/32] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:35:23 ViT-B/32] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/32)
[2025-03-03 09:35:25 ViT-B/32] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:35:25 ViT-B/32] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:35:25 ViT-B/32] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:35:26 ViT-B/32] (2665388570.py 1): INFO ==============> Resuming form output/crossvalidation/vitb16_2/fold1/ckpt_epoch_0.pth....................
[2025-03-03 09:38:10 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:38:12 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:38:13 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:38:13 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:38:13 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:38:15 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form output/crossvalidation/vitb16_2/fold1/ckpt_epoch_0.pth....................
[2025-03-03 09:38:16 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:38:50 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:38:51 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:38:53 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:38:53 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:38:53 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:38:53 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form output/crossvalidation/vitb16_2/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:38:53 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:41:13 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:41:14 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:41:15 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:41:15 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:41:15 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:41:16 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 09:41:36 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:42:05 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:42:06 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:42:07 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:42:07 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:42:07 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:42:07 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:42:27 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:56:51 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:56:56 ViT-B/16] (vificlip.py 269): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:56:58 ViT-B/16] (vificlip.py 272): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:56:58 ViT-B/16] (vificlip.py 290): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:56:58 ViT-B/16] (vificlip.py 314): INFO Total learnable items: 302
[2025-03-03 09:57:03 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:57:05 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 09:58:38 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:58:38 ViT-B/16] (vificlip.py 269): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:58:40 ViT-B/16] (vificlip.py 272): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:58:40 ViT-B/16] (vificlip.py 290): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:58:40 ViT-B/16] (vificlip.py 314): INFO Total learnable items: 302
[2025-03-03 09:58:41 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:58:42 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 09:59:24 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:59:24 ViT-B/16] (vificlip.py 269): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:59:26 ViT-B/16] (vificlip.py 272): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:59:26 ViT-B/16] (vificlip.py 290): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:59:26 ViT-B/16] (vificlip.py 314): INFO Total learnable items: 302
[2025-03-03 09:59:28 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:59:28 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:00:49 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:00:49 ViT-B/16] (vificlip.py 273): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:00:51 ViT-B/16] (vificlip.py 276): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:00:51 ViT-B/16] (vificlip.py 294): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:00:51 ViT-B/16] (vificlip.py 318): INFO Total learnable items: 302
[2025-03-03 10:00:52 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 10:00:53 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:01:27 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:01:27 ViT-B/16] (vificlip.py 273): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:01:29 ViT-B/16] (vificlip.py 276): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:01:29 ViT-B/16] (vificlip.py 294): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:01:29 ViT-B/16] (vificlip.py 318): INFO Total learnable items: 302
[2025-03-03 10:01:29 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 10:01:30 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:05:25 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:05:26 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:05:27 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:05:27 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:05:27 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-03 10:05:29 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 10:05:30 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:06:03 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:06:04 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:06:05 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:06:05 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:06:05 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-03 10:06:07 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 10:06:08 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:06:18 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:06:18 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:06:20 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:06:20 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:06:20 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-03 10:06:20 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 10:06:20 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
