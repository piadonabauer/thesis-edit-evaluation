[2025-03-12 21:12:16 ViT-B/16] (main.py 348): INFO working dir: output/scalability
[2025-03-12 21:12:16 ViT-B/16] (main.py 352): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  DATASET: humanedit
  INPUT_SIZE: 224
  LABEL_LIST: /home/jovyan/BA/Github/thesis-edit-evaluation/data/humanedit/labels.csv
  NUM_CLASSES: 4534
  NUM_FRAMES: 2
  ROOT: /home/jovyan/BA/Github/HumanEdit/videos
  TRAIN_FILE: /home/jovyan/BA/Github/HumanEdit/train_1k.txt
  VAL_FILE: /home/jovyan/BA/Github/HumanEdit/test_20.txt
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  PRETRAINED: None
  RESUME: None
OUTPUT: output/scalability
PRINT_FREQ: 50
SAVE_FREQ: 10
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: False
  BATCH_SIZE: 16
  EPOCHS: 11
  LR: 2e-06
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 5
  WEIGHT_DECAY: 0.001
TRAINER:
  ViFi_CLIP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
VAL_FREQ: 1
[2025-03-12 21:12:16 ViT-B/16] (vificlip.py 242): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-12 21:12:17 ViT-B/16] (vificlip.py 245): INFO Building ViFi-CLIP CLIP
[2025-03-12 21:12:18 ViT-B/16] (vificlip.py 262): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-12 21:12:18 ViT-B/16] (vificlip.py 286): INFO Total learnable items: 302
[2025-03-12 21:12:22 ViT-B/16] (main.py 184): INFO Train: [0/11][0/62]	eta 0:03:26 lr 0.000000000	time 3.3366 (3.3366)	tot_loss 4.3126 (4.3126)	mem 6882MB
[2025-03-12 21:14:02 ViT-B/16] (main.py 184): INFO Train: [0/11][50/62]	eta 0:00:24 lr 0.000000316	time 2.1166 (2.0256)	tot_loss 4.4875 (3.9982)	mem 7887MB
[2025-03-12 21:14:25 ViT-B/16] (main.py 191): INFO EPOCH 0 training takes 0:02:06
[2025-03-12 21:14:25 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 21:15:31 ViT-B/16] (main.py 348): INFO working dir: output/scalability
[2025-03-12 21:15:31 ViT-B/16] (main.py 352): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  DATASET: humanedit
  INPUT_SIZE: 224
  LABEL_LIST: /home/jovyan/BA/Github/thesis-edit-evaluation/data/humanedit/labels.csv
  NUM_CLASSES: 4534
  NUM_FRAMES: 2
  ROOT: /home/jovyan/BA/Github/HumanEdit/videos
  TRAIN_FILE: /home/jovyan/BA/Github/HumanEdit/train_1k.txt
  VAL_FILE: /home/jovyan/BA/Github/HumanEdit/test_20.txt
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  PRETRAINED: None
  RESUME: None
OUTPUT: output/scalability
PRINT_FREQ: 50
SAVE_FREQ: 10
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: False
  BATCH_SIZE: 32
  EPOCHS: 11
  LR: 2e-06
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 5
  WEIGHT_DECAY: 0.001
TRAINER:
  ViFi_CLIP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
VAL_FREQ: 1
[2025-03-12 21:15:31 ViT-B/16] (vificlip.py 242): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-12 21:15:32 ViT-B/16] (vificlip.py 245): INFO Building ViFi-CLIP CLIP
[2025-03-12 21:15:33 ViT-B/16] (vificlip.py 262): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-12 21:15:33 ViT-B/16] (vificlip.py 286): INFO Total learnable items: 302
[2025-03-12 21:15:54 ViT-B/16] (main.py 348): INFO working dir: output/scalability
[2025-03-12 21:15:54 ViT-B/16] (main.py 352): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  DATASET: humanedit
  INPUT_SIZE: 224
  LABEL_LIST: /home/jovyan/BA/Github/thesis-edit-evaluation/data/humanedit/labels.csv
  NUM_CLASSES: 4534
  NUM_FRAMES: 2
  ROOT: /home/jovyan/BA/Github/HumanEdit/videos
  TRAIN_FILE: /home/jovyan/BA/Github/HumanEdit/train_1k.txt
  VAL_FILE: /home/jovyan/BA/Github/HumanEdit/test_20.txt
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  PRETRAINED: None
  RESUME: None
OUTPUT: output/scalability
PRINT_FREQ: 50
SAVE_FREQ: 10
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: False
  BATCH_SIZE: 16
  EPOCHS: 11
  LR: 2e-06
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 5
  WEIGHT_DECAY: 0.001
TRAINER:
  ViFi_CLIP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
VAL_FREQ: 1
[2025-03-12 21:15:54 ViT-B/16] (vificlip.py 242): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-12 21:15:56 ViT-B/16] (vificlip.py 245): INFO Building ViFi-CLIP CLIP
[2025-03-12 21:15:56 ViT-B/16] (vificlip.py 262): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-12 21:15:56 ViT-B/16] (vificlip.py 286): INFO Total learnable items: 302
[2025-03-12 21:16:00 ViT-B/16] (main.py 184): INFO Train: [0/11][0/62]	eta 0:03:29 lr 0.000000000	time 3.3739 (3.3739)	tot_loss 4.3126 (4.3126)	mem 6882MB
[2025-03-12 21:17:46 ViT-B/16] (main.py 184): INFO Train: [0/11][50/62]	eta 0:00:25 lr 0.000000316	time 2.1454 (2.1353)	tot_loss 4.4875 (3.9982)	mem 7888MB
[2025-03-12 21:18:10 ViT-B/16] (main.py 191): INFO EPOCH 0 training takes 0:02:12
[2025-03-12 21:18:10 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 21:36:15 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 21:36:15 ViT-B/16] (main.py 300): INFO  * Loss: 8.3890
[2025-03-12 21:36:15 ViT-B/16] (main.py 301): INFO  * Mean Rank: 282.554, Median Rank: 79.000
[2025-03-12 21:36:15 ViT-B/16] (main.py 302): INFO  * Recall@1: 6.915, Recall@5: 17.642, Recall@10: 25.089, Recall@50: 43.085
[2025-03-12 21:36:15 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 6.9%
[2025-03-12 21:36:15 ViT-B/16] (main.py 114): INFO Max accuracy: 6.91%
[2025-03-12 21:36:15 ViT-B/16] (tools.py 55): INFO output/scalability/ckpt_epoch_0.pth saving......
[2025-03-12 21:36:34 ViT-B/16] (tools.py 57): INFO output/scalability/ckpt_epoch_0.pth saved !!!
[2025-03-12 21:36:53 ViT-B/16] (tools.py 61): INFO output/scalability/best.pth saved !!!
[2025-03-12 21:36:56 ViT-B/16] (main.py 184): INFO Train: [1/11][0/62]	eta 0:03:06 lr 0.000000394	time 3.0117 (3.0117)	tot_loss 3.8618 (3.8618)	mem 7888MB
[2025-03-12 21:38:43 ViT-B/16] (main.py 184): INFO Train: [1/11][50/62]	eta 0:00:25 lr 0.000000716	time 2.1580 (2.1494)	tot_loss 3.6706 (3.8874)	mem 7888MB
[2025-03-12 21:39:07 ViT-B/16] (main.py 191): INFO EPOCH 1 training takes 0:02:13
[2025-03-12 21:39:07 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 21:57:11 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 21:57:11 ViT-B/16] (main.py 300): INFO  * Loss: 8.3939
[2025-03-12 21:57:11 ViT-B/16] (main.py 301): INFO  * Mean Rank: 272.572, Median Rank: 67.000
[2025-03-12 21:57:11 ViT-B/16] (main.py 302): INFO  * Recall@1: 6.472, Recall@5: 18.085, Recall@10: 25.709, Recall@50: 45.124
[2025-03-12 21:57:11 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 6.5%
[2025-03-12 21:57:11 ViT-B/16] (main.py 114): INFO Max accuracy: 6.91%
[2025-03-12 21:57:14 ViT-B/16] (main.py 184): INFO Train: [2/11][0/62]	eta 0:03:16 lr 0.000000794	time 3.1664 (3.1664)	tot_loss 3.1112 (3.1112)	mem 7888MB
[2025-03-12 21:59:01 ViT-B/16] (main.py 184): INFO Train: [2/11][50/62]	eta 0:00:25 lr 0.000001116	time 2.1206 (2.1439)	tot_loss 3.6254 (3.6575)	mem 7888MB
[2025-03-12 21:59:24 ViT-B/16] (main.py 191): INFO EPOCH 2 training takes 0:02:12
[2025-03-12 21:59:24 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 22:17:26 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 22:17:26 ViT-B/16] (main.py 300): INFO  * Loss: 8.3981
[2025-03-12 22:17:26 ViT-B/16] (main.py 301): INFO  * Mean Rank: 274.739, Median Rank: 58.000
[2025-03-12 22:17:26 ViT-B/16] (main.py 302): INFO  * Recall@1: 5.851, Recall@5: 18.174, Recall@10: 26.152, Recall@50: 47.340
[2025-03-12 22:17:26 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 5.9%
[2025-03-12 22:17:26 ViT-B/16] (main.py 114): INFO Max accuracy: 6.91%
[2025-03-12 22:17:29 ViT-B/16] (main.py 184): INFO Train: [3/11][0/62]	eta 0:03:11 lr 0.000001194	time 3.0876 (3.0876)	tot_loss 3.4701 (3.4701)	mem 7888MB
[2025-03-12 22:19:15 ViT-B/16] (main.py 184): INFO Train: [3/11][50/62]	eta 0:00:25 lr 0.000001516	time 2.1155 (2.1412)	tot_loss 4.0545 (3.6475)	mem 7888MB
[2025-03-12 22:19:38 ViT-B/16] (main.py 191): INFO EPOCH 3 training takes 0:02:12
[2025-03-12 22:19:38 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 22:37:39 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 22:37:39 ViT-B/16] (main.py 300): INFO  * Loss: 8.3977
[2025-03-12 22:37:39 ViT-B/16] (main.py 301): INFO  * Mean Rank: 260.374, Median Rank: 58.000
[2025-03-12 22:37:39 ViT-B/16] (main.py 302): INFO  * Recall@1: 6.915, Recall@5: 18.972, Recall@10: 26.862, Recall@50: 48.138
[2025-03-12 22:37:39 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 6.9%
[2025-03-12 22:37:39 ViT-B/16] (main.py 114): INFO Max accuracy: 6.91%
[2025-03-12 22:37:42 ViT-B/16] (main.py 184): INFO Train: [4/11][0/62]	eta 0:03:12 lr 0.000001594	time 3.1018 (3.1018)	tot_loss 3.8107 (3.8107)	mem 7888MB
[2025-03-12 22:39:28 ViT-B/16] (main.py 184): INFO Train: [4/11][50/62]	eta 0:00:25 lr 0.000001916	time 2.1168 (2.1390)	tot_loss 3.7479 (3.5374)	mem 7888MB
[2025-03-12 22:39:51 ViT-B/16] (main.py 191): INFO EPOCH 4 training takes 0:02:12
[2025-03-12 22:39:51 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 22:57:51 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 22:57:51 ViT-B/16] (main.py 300): INFO  * Loss: 8.3970
[2025-03-12 22:57:51 ViT-B/16] (main.py 301): INFO  * Mean Rank: 249.730, Median Rank: 53.000
[2025-03-12 22:57:51 ViT-B/16] (main.py 302): INFO  * Recall@1: 7.447, Recall@5: 20.035, Recall@10: 27.660, Recall@50: 49.291
[2025-03-12 22:57:51 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 7.4%
[2025-03-12 22:57:51 ViT-B/16] (main.py 114): INFO Max accuracy: 7.45%
[2025-03-12 22:57:51 ViT-B/16] (tools.py 55): INFO output/scalability/ckpt_epoch_4.pth saving......
[2025-03-12 22:58:10 ViT-B/16] (tools.py 57): INFO output/scalability/ckpt_epoch_4.pth saved !!!
[2025-03-12 22:58:30 ViT-B/16] (tools.py 61): INFO output/scalability/best.pth saved !!!
[2025-03-12 22:58:33 ViT-B/16] (main.py 184): INFO Train: [5/11][0/62]	eta 0:03:01 lr 0.000001994	time 2.9216 (2.9216)	tot_loss 3.4208 (3.4208)	mem 7888MB
[2025-03-12 23:00:19 ViT-B/16] (main.py 184): INFO Train: [5/11][50/62]	eta 0:00:25 lr 0.000000928	time 2.1442 (2.1420)	tot_loss 3.6877 (3.5086)	mem 7888MB
[2025-03-12 23:00:43 ViT-B/16] (main.py 191): INFO EPOCH 5 training takes 0:02:13
[2025-03-12 23:00:43 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 23:18:44 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 23:18:44 ViT-B/16] (main.py 300): INFO  * Loss: 8.3973
[2025-03-12 23:18:44 ViT-B/16] (main.py 301): INFO  * Mean Rank: 244.596, Median Rank: 50.000
[2025-03-12 23:18:44 ViT-B/16] (main.py 302): INFO  * Recall@1: 7.358, Recall@5: 20.479, Recall@10: 27.660, Recall@50: 50.621
[2025-03-12 23:18:44 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 7.4%
[2025-03-12 23:18:44 ViT-B/16] (main.py 114): INFO Max accuracy: 7.45%
[2025-03-12 23:18:48 ViT-B/16] (main.py 184): INFO Train: [6/11][0/62]	eta 0:03:10 lr 0.000000874	time 3.0767 (3.0767)	tot_loss 3.0643 (3.0643)	mem 7888MB
[2025-03-12 23:20:33 ViT-B/16] (main.py 184): INFO Train: [6/11][50/62]	eta 0:00:25 lr 0.000000653	time 2.1101 (2.1384)	tot_loss 3.7569 (3.3970)	mem 7888MB
[2025-03-12 23:20:57 ViT-B/16] (main.py 191): INFO EPOCH 6 training takes 0:02:12
[2025-03-12 23:20:57 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 23:38:56 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 23:38:56 ViT-B/16] (main.py 300): INFO  * Loss: 8.3973
[2025-03-12 23:38:56 ViT-B/16] (main.py 301): INFO  * Mean Rank: 240.617, Median Rank: 51.000
[2025-03-12 23:38:56 ViT-B/16] (main.py 302): INFO  * Recall@1: 7.979, Recall@5: 20.833, Recall@10: 27.926, Recall@50: 50.000
[2025-03-12 23:38:56 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 8.0%
[2025-03-12 23:38:56 ViT-B/16] (main.py 114): INFO Max accuracy: 7.98%
[2025-03-12 23:38:56 ViT-B/16] (tools.py 55): INFO output/scalability/ckpt_epoch_6.pth saving......
[2025-03-12 23:39:15 ViT-B/16] (tools.py 57): INFO output/scalability/ckpt_epoch_6.pth saved !!!
[2025-03-12 23:39:34 ViT-B/16] (tools.py 61): INFO output/scalability/best.pth saved !!!
[2025-03-12 23:39:37 ViT-B/16] (main.py 184): INFO Train: [7/11][0/62]	eta 0:03:03 lr 0.000000603	time 2.9596 (2.9596)	tot_loss 3.4396 (3.4396)	mem 7888MB
[2025-03-12 23:41:24 ViT-B/16] (main.py 184): INFO Train: [7/11][50/62]	eta 0:00:25 lr 0.000000408	time 2.1507 (2.1426)	tot_loss 3.7805 (3.3601)	mem 7888MB
[2025-03-12 23:41:47 ViT-B/16] (main.py 191): INFO EPOCH 7 training takes 0:02:13
[2025-03-12 23:41:47 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-12 23:59:48 ViT-B/16] (main.py 299): INFO Validation
[2025-03-12 23:59:48 ViT-B/16] (main.py 300): INFO  * Loss: 8.3957
[2025-03-12 23:59:48 ViT-B/16] (main.py 301): INFO  * Mean Rank: 233.264, Median Rank: 49.000
[2025-03-12 23:59:48 ViT-B/16] (main.py 302): INFO  * Recall@1: 7.890, Recall@5: 20.833, Recall@10: 28.014, Recall@50: 50.532
[2025-03-12 23:59:48 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 7.9%
[2025-03-12 23:59:48 ViT-B/16] (main.py 114): INFO Max accuracy: 7.98%
[2025-03-12 23:59:51 ViT-B/16] (main.py 184): INFO Train: [8/11][0/62]	eta 0:03:13 lr 0.000000365	time 3.1183 (3.1183)	tot_loss 2.9527 (2.9527)	mem 7888MB
[2025-03-13 00:01:37 ViT-B/16] (main.py 184): INFO Train: [8/11][50/62]	eta 0:00:25 lr 0.000000211	time 2.1109 (2.1363)	tot_loss 3.5251 (3.3990)	mem 7888MB
[2025-03-13 00:02:00 ViT-B/16] (main.py 191): INFO EPOCH 8 training takes 0:02:12
[2025-03-13 00:02:00 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-13 00:19:58 ViT-B/16] (main.py 299): INFO Validation
[2025-03-13 00:19:58 ViT-B/16] (main.py 300): INFO  * Loss: 8.3962
[2025-03-13 00:19:58 ViT-B/16] (main.py 301): INFO  * Mean Rank: 232.642, Median Rank: 49.000
[2025-03-13 00:19:58 ViT-B/16] (main.py 302): INFO  * Recall@1: 8.245, Recall@5: 20.745, Recall@10: 28.191, Recall@50: 50.443
[2025-03-13 00:19:58 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 8.2%
[2025-03-13 00:19:58 ViT-B/16] (main.py 114): INFO Max accuracy: 8.24%
[2025-03-13 00:19:58 ViT-B/16] (tools.py 55): INFO output/scalability/ckpt_epoch_8.pth saving......
[2025-03-13 00:20:17 ViT-B/16] (tools.py 57): INFO output/scalability/ckpt_epoch_8.pth saved !!!
[2025-03-13 00:20:36 ViT-B/16] (tools.py 61): INFO output/scalability/best.pth saved !!!
[2025-03-13 00:20:40 ViT-B/16] (main.py 184): INFO Train: [9/11][0/62]	eta 0:03:09 lr 0.000000180	time 3.0546 (3.0546)	tot_loss 3.7802 (3.7802)	mem 7888MB
[2025-03-13 00:22:26 ViT-B/16] (main.py 184): INFO Train: [9/11][50/62]	eta 0:00:25 lr 0.000000078	time 2.1454 (2.1407)	tot_loss 3.8603 (3.3459)	mem 7888MB
[2025-03-13 00:22:49 ViT-B/16] (main.py 191): INFO EPOCH 9 training takes 0:02:12
[2025-03-13 00:22:49 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-13 00:40:49 ViT-B/16] (main.py 299): INFO Validation
[2025-03-13 00:40:49 ViT-B/16] (main.py 300): INFO  * Loss: 8.3965
[2025-03-13 00:40:49 ViT-B/16] (main.py 301): INFO  * Mean Rank: 233.125, Median Rank: 49.000
[2025-03-13 00:40:49 ViT-B/16] (main.py 302): INFO  * Recall@1: 8.245, Recall@5: 21.011, Recall@10: 28.635, Recall@50: 50.443
[2025-03-13 00:40:49 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 8.2%
[2025-03-13 00:40:49 ViT-B/16] (main.py 114): INFO Max accuracy: 8.24%
[2025-03-13 00:40:52 ViT-B/16] (main.py 184): INFO Train: [10/11][0/62]	eta 0:03:12 lr 0.000000061	time 3.1083 (3.1083)	tot_loss 3.5082 (3.5082)	mem 7888MB
[2025-03-13 00:42:38 ViT-B/16] (main.py 184): INFO Train: [10/11][50/62]	eta 0:00:25 lr 0.000000022	time 2.1084 (2.1357)	tot_loss 3.5807 (3.3894)	mem 7888MB
[2025-03-13 00:43:02 ViT-B/16] (main.py 191): INFO EPOCH 10 training takes 0:02:12
[2025-03-13 00:43:02 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-13 01:00:59 ViT-B/16] (main.py 299): INFO Validation
[2025-03-13 01:00:59 ViT-B/16] (main.py 300): INFO  * Loss: 8.3963
[2025-03-13 01:00:59 ViT-B/16] (main.py 301): INFO  * Mean Rank: 232.698, Median Rank: 49.000
[2025-03-13 01:00:59 ViT-B/16] (main.py 302): INFO  * Recall@1: 8.245, Recall@5: 21.011, Recall@10: 28.635, Recall@50: 50.709
[2025-03-13 01:00:59 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 8.2%
[2025-03-13 01:00:59 ViT-B/16] (main.py 114): INFO Max accuracy: 8.24%
[2025-03-13 01:00:59 ViT-B/16] (tools.py 55): INFO output/scalability/ckpt_epoch_10.pth saving......
[2025-03-13 01:01:18 ViT-B/16] (tools.py 57): INFO output/scalability/ckpt_epoch_10.pth saved !!!
