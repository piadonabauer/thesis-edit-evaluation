[2025-03-03 09:32:46 ViT-B/16] (2516783699.py 19): INFO working dir: exp
[2025-03-03 09:32:55 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:32:57 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:32:57 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:32:57 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:33:45 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form None....................
[2025-03-03 09:34:35 ViT-B/32] (2516783699.py 19): INFO working dir: exp
[2025-03-03 09:34:37 ViT-B/32] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/32)
[2025-03-03 09:34:38 ViT-B/32] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:34:38 ViT-B/32] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:34:38 ViT-B/32] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:34:39 ViT-B/32] (2665388570.py 1): INFO ==============> Resuming form None....................
[2025-03-03 09:35:04 ViT-B/32] (2071167465.py 1): INFO ==============> Resuming form None....................
[2025-03-03 09:35:20 ViT-B/32] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:35:23 ViT-B/32] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/32)
[2025-03-03 09:35:25 ViT-B/32] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:35:25 ViT-B/32] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:35:25 ViT-B/32] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:35:26 ViT-B/32] (2665388570.py 1): INFO ==============> Resuming form output/crossvalidation/vitb16_2/fold1/ckpt_epoch_0.pth....................
[2025-03-03 09:38:10 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:38:12 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:38:13 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:38:13 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:38:13 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:38:15 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form output/crossvalidation/vitb16_2/fold1/ckpt_epoch_0.pth....................
[2025-03-03 09:38:16 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:38:50 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:38:51 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:38:53 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:38:53 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:38:53 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:38:53 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form output/crossvalidation/vitb16_2/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:38:53 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:41:13 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:41:14 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:41:15 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:41:15 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:41:15 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:41:16 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 09:41:36 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:42:05 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:42:06 ViT-B/16] (vificlip.py 215): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:42:07 ViT-B/16] (vificlip.py 218): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:42:07 ViT-B/16] (vificlip.py 235): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:42:07 ViT-B/16] (vificlip.py 259): INFO Total learnable items: 301
[2025-03-03 09:42:07 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:42:27 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])
[2025-03-03 09:56:51 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:56:56 ViT-B/16] (vificlip.py 269): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:56:58 ViT-B/16] (vificlip.py 272): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:56:58 ViT-B/16] (vificlip.py 290): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:56:58 ViT-B/16] (vificlip.py 314): INFO Total learnable items: 302
[2025-03-03 09:57:03 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:57:05 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 09:58:38 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:58:38 ViT-B/16] (vificlip.py 269): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:58:40 ViT-B/16] (vificlip.py 272): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:58:40 ViT-B/16] (vificlip.py 290): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:58:40 ViT-B/16] (vificlip.py 314): INFO Total learnable items: 302
[2025-03-03 09:58:41 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:58:42 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 09:59:24 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 09:59:24 ViT-B/16] (vificlip.py 269): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 09:59:26 ViT-B/16] (vificlip.py 272): INFO Building ViFi-CLIP CLIP
[2025-03-03 09:59:26 ViT-B/16] (vificlip.py 290): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 09:59:26 ViT-B/16] (vificlip.py 314): INFO Total learnable items: 302
[2025-03-03 09:59:28 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 09:59:28 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:00:49 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:00:49 ViT-B/16] (vificlip.py 273): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:00:51 ViT-B/16] (vificlip.py 276): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:00:51 ViT-B/16] (vificlip.py 294): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:00:51 ViT-B/16] (vificlip.py 318): INFO Total learnable items: 302
[2025-03-03 10:00:52 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 10:00:53 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:01:27 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:01:27 ViT-B/16] (vificlip.py 273): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:01:29 ViT-B/16] (vificlip.py 276): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:01:29 ViT-B/16] (vificlip.py 294): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:01:29 ViT-B/16] (vificlip.py 318): INFO Total learnable items: 302
[2025-03-03 10:01:29 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 10:01:30 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:05:25 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:05:26 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:05:27 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:05:27 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:05:27 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-03 10:05:29 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 10:05:30 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:06:03 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:06:04 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:06:05 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:06:05 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:06:05 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-03 10:06:07 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_1.pth....................
[2025-03-03 10:06:08 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-03 10:06:18 ViT-B/16] (588939814.py 19): INFO working dir: exp
[2025-03-03 10:06:18 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-03 10:06:20 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-03 10:06:20 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-03 10:06:20 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-03 10:06:20 ViT-B/16] (2665388570.py 1): INFO ==============> Resuming form /home/jovyan/BA/Github/thesis-edit-evaluation/ViFi-CLIP-og/output/cross_validation/vitb16_2_humanedit_freeze_none/fold1/ckpt_epoch_10.pth....................
[2025-03-03 10:06:20 ViT-B/16] (3852643250.py 3): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-08 20:15:46 ViT-B/16] (vificlip.py 228): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-08 20:15:48 ViT-B/16] (vificlip.py 231): INFO Building ViFi-CLIP CLIP
[2025-03-08 20:15:48 ViT-B/16] (vificlip.py 248): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-08 20:15:48 ViT-B/16] (vificlip.py 272): INFO Total learnable items: 302
[2025-03-08 20:16:09 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:33:20 ViT-B/16] (vificlip.py 231): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:33:22 ViT-B/16] (vificlip.py 234): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:33:22 ViT-B/16] (vificlip.py 251): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:33:22 ViT-B/16] (vificlip.py 275): INFO Total learnable items: 302
[2025-03-09 13:33:23 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:34:16 ViT-B/16] (vificlip.py 229): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:34:18 ViT-B/16] (vificlip.py 232): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:34:18 ViT-B/16] (vificlip.py 249): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:34:18 ViT-B/16] (vificlip.py 273): INFO Total learnable items: 302
[2025-03-09 13:34:19 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:34:19 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark', 'hallo']
[2025-03-09 13:34:30 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark']
[2025-03-09 13:34:33 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark']
[2025-03-09 13:34:39 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark', 'und']
[2025-03-09 13:37:27 ViT-B/16] (vificlip.py 239): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:37:29 ViT-B/16] (vificlip.py 242): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:37:29 ViT-B/16] (vificlip.py 259): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:37:29 ViT-B/16] (vificlip.py 283): INFO Total learnable items: 302
[2025-03-09 13:37:30 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:37:30 ViT-B/16] (vificlip.py 184): INFO ['let the cabinets be made of dark', 'und']
[2025-03-09 13:38:15 ViT-B/16] (vificlip.py 240): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:38:16 ViT-B/16] (vificlip.py 243): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:38:16 ViT-B/16] (vificlip.py 260): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:38:16 ViT-B/16] (vificlip.py 284): INFO Total learnable items: 302
[2025-03-09 13:38:18 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:38:18 ViT-B/16] (vificlip.py 184): INFO ['let the cabinets be made of dark', 'und']
[2025-03-09 13:38:23 ViT-B/16] (vificlip.py 184): INFO ['let the cabinets be made of dark']
[2025-03-09 13:38:28 ViT-B/16] (vificlip.py 184): INFO ['let the cabinets be made of']
[2025-03-09 13:42:13 ViT-B/16] (vificlip.py 232): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:42:14 ViT-B/16] (vificlip.py 235): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:42:14 ViT-B/16] (vificlip.py 252): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:42:14 ViT-B/16] (vificlip.py 276): INFO Total learnable items: 302
[2025-03-09 13:42:16 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:42:16 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of']
[2025-03-09 13:42:22 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of', 'hi']
[2025-03-09 13:42:25 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of', 'bye']
[2025-03-09 13:42:31 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of', 'kitchen']
[2025-03-09 13:42:36 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of', 'bathroom']
[2025-03-09 13:42:40 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of', 'bedroom']
[2025-03-09 13:42:50 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of', 'add a table']
[2025-03-09 13:42:54 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of wood', 'add a table']
[2025-03-09 13:42:58 ViT-B/16] (vificlip.py 183): INFO ['cabinets be made of wood', 'add a table']
[2025-03-09 13:43:01 ViT-B/16] (vificlip.py 183): INFO ['cabinets wood', 'add a table']
[2025-03-09 13:43:07 ViT-B/16] (vificlip.py 183): INFO ['add wooden cabinets', 'add a table']
[2025-03-09 13:43:15 ViT-B/16] (vificlip.py 183): INFO ['make the cabinets wooden', 'add a table']
[2025-03-09 13:44:06 ViT-B/16] (vificlip.py 232): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:44:07 ViT-B/16] (vificlip.py 235): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:44:07 ViT-B/16] (vificlip.py 252): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:44:07 ViT-B/16] (vificlip.py 276): INFO Total learnable items: 302
[2025-03-09 13:44:08 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['what if the vegetables are in a bowl?']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ["let's add a drawing of a flower to the fridge"]
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let the sun shine']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['it could be a microwave next to the woman']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['can it be a boy not a girl?']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['could the woman hold a banana?']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let the vehicle be replaced by a bicycle']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['a girl is eating cereal']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let the woman drink wine']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['add a bus station']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['add people']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['add an airplane']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['what if the boy was bald?']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let a forest be the background']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let the player wear a red hat']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['change the toothpicks into candles']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let the plate be made of glass']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['let the sandwich be vegan']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['give the girl a baseball bat instead of a racket']
[2025-03-09 13:44:08 ViT-B/16] (vificlip.py 183): INFO ['remove the tennis ball']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['give her a baseball cap']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['get rid of the racket']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['give her jean pants']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['add a cyclist on the street']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the bus for a school bus']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['add a dog walking in front of the guy']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['can it be a cake on the plate?']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['put a donut next to the cake']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['can we have a glass of soda next to the plate?']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the cat have a short tail']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['replace it with a black dog']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['remove one of its eyes']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['give it a hat']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the woman smile']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ["let's add a rat next to the pizza"]
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the hair color to pink']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['put a whale in the water']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['put a policeman in the intersection']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['turn the remote into a pizza']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['give the man glasses']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the jam be changed to strawberry one']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['add a turtle']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the wooden cabinetry to steel']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the wood floor to tiled floor']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['add soda cans on the counter']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let there be pigs in the pen']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['remove the fence']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let a child point at the animals']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the horse eat a carrot without the bag']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let a penguin look at the horse']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the horse close its eyes']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the woman cry']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the woman have blonde hair']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the woman hold a cup']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the fruit be sliced bananas']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let a plate contain sliced bread']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the plates be on a wooden table']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the stuffed toys into rubber duckies']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the dogs sleep in a basket']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let a spider be in the basket']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the text on the parking meter to say "no"']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['have there be a digital display on the parking meters']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['give the bird a long tail']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['add flowers']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['have baby birds follow the large bird']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ["change the table's color to red"]
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ["let's give him a yellow shirt"]
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['change the swimsuit color to green']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the arabic writing be changed to chinese']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['add a car instead of motorcycles']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['edit the background by removing the museum and placing a castle']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['replace the stuffed animals with a pillow']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the monitor turn black']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['replace the donuts with fruits']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let a woman in a bridal gown stand near the cake']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let there be heart shaped balloons']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ["let's add a cat on the roof"]
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the fence be made of wood']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the cat wear a bow tie instead of a tie']
[2025-03-09 13:44:09 ViT-B/16] (vificlip.py 183): INFO ['let the cat have blue eyes']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the cat lay on a wooden floor instead of a carpet']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the ball']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the bat']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the batter']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the woman kiss']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the woman make a heart sign with her hands']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the bowl have chocolate sauce']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['open the lid of a toilet']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['replace the chocolate with berries']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['add a lizard on the counter']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the plate contain ice cream']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['get rid of the cat']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['put a vase on top of the table']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['get rid of the vase on top of the table']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ["let's add a cowboy hat to the giraffe"]
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog in the grass"]
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let a cat be near the hydrant']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the hydrant be small and red']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a pickup truck']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['swap the kites with drones']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['turn the mountain in a waterfall']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['a parakeet should be sitting on the knit item']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['a cat should be watching the parakeet while sitting in a flower pot']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['the cat should have a hat on']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['make the apples green']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['get rid of the jar of cookies']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['make the cake a chocolate cake']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the man press the keyboard']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['what if the child was holding a bottle of peper?']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['what if there was a drawing of a bird on his shirt?']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['the car should be white']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['put a red sign insted of the bike']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['put a ball on the sidewalk']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['change the trees to palm trees']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the people']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['put a parking meter next to the bus']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['put a penguin near the polar bears']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['change the clock tower to a bell tower']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the patch of flowers be daffodils']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['add a rocket in the sky']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the surfboard be green']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the words']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['add a shark next to the surfboard']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['have a cruise ship pull into the harbor']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['add hot air balloons']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the kid sleep']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['give the person a bowl']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the older man have dark hair']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the ladies wear red dresses']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the older man wear a cowboy hat']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ["make the man's top blue"]
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the frisbee']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['make all the grass green']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow letters']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['change the usa flag into a japanese flag']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let a pilot walk next to the plane']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['let the van turn black']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ["split the top layer so there's an extra one"]
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['put bride and groom toppers on it']
[2025-03-09 13:44:10 ViT-B/16] (vificlip.py 183): INFO ['remove the frosting between layers']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put a tennis racket next to the bat']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['get rid of the baseball bat']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let there be a game show on tv']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let there be granite floor in the kitchen']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark wood']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['turn the frisbee into a soccer ball']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the dog have a newspaper in its mouth']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let there be potted plant']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['make the zebra a regular horse']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the blood orange be swapped with an apple']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change the ski gear into a scuba gear']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the tree be conifers']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add a polar bear']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the man cut pizza with a knife']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['make it a pepperoni pizza']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the man have a tattoo on his hand']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the bluebery cake be topped with chocolate syrup']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the drink be replaced by a glass of milk']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change the truck into a taxi']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let a herd of sheep block the taxi']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change the trees at the back into palm trees']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put strawberry on the plate']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['leave nothing on top of the cheesecake']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['make the man ride a motorcycle instead of a bicycle']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['swap the surfboard for a skateboard']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the couch be an expensive leather one']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the window show a garden']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have wooden beams']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a battle tank']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let a man run towards the tank']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let there be an oak tree']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog next to the cows"]
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add a cup of coffee']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['remove the salad on the side']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let a green towel be hung in the bathroom']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add cookies to the tray']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change the bag of chips into a backpack']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['remove the playstation controller']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['remove one of the pizzas']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change the toppings to pepperoni and cheese']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put a lion in the place of the donkey']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['turn the basin into a plastic pool']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the ship be blue']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add a cat']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add a table in front']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['have there be a basket of fruit on the counter']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['take the objects off the dresser']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['change kids to men']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add a dog catching a ball']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['add a rainbow in the sky']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put popcorn in the plate']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ["make the dog's eyes closed"]
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put skis on the wheel']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put a wooden floor on the kitchen']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put a table on the kitchen']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['put a microwave on the counter']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['let the carpet be changed to wooden floor']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['an airplane is smoking from the cockpit']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['it should be just one cow']
[2025-03-09 13:44:11 ViT-B/16] (vificlip.py 183): INFO ['could it be a river on the background?']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add a goat next to the cow']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the tea into cappuccino']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the sandwich to salad']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add a bottle of sauce']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the plane further away']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['replace the cart with an upright one']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['replace the traffic meter with a pole']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['put a puppy in the cart']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['there should be a tree on the front']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['it should be a mountain in the background']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['the trash can should be blue']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['cover the bread with sauce and salad']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add a glass of water']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the fork to a spoon']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['have a fly sit on the laptop']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the scarf multi-colored']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the woman smile']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ["make the woman's hair more straightened out"]
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the vegetables into broccoli']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let the sandwiches be changed to risotto']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let the apples be changed to orange slices']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let water run from the faucet']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['remove the car']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['replace the sign with a stop sign']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['put a squirrel on top of the sign']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the woman hold a camera']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['give the woman another camera']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let the cup contain flowers']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let there be a bug on the wood']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the scooter into a skateboard']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let the tree have lush green leaves']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let the boy wear a superhero costume']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the washington monument with the statue of liberty']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add flying eagles over the statue']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the recording devices to makeup']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the laptop into a makeup tray']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the wood desk a white table']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the flowers on the wallet to be white']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['have there be a bee on the wallet']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the cows']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['can we have mountains on the background?']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['put a horse insted of the goats']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let the elephant turn young']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['take the papers out the table']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the glass of water a to go cup']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the tables to a playland']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the red lights to green lights']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add a truck on the street']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['remove the trees']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a stuffed action figure toy']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['let a child play nearby']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add a cat on the top of a counter']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['change the yellow lights to white lights']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['add a champagne bottle']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['remove that sink']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['the bed should be red']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['put a pile of shoes next to the bed']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['could we have a window next to the bed?']
[2025-03-09 13:44:12 ViT-B/16] (vificlip.py 183): INFO ['make the toilet pink']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['remove the apple']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['give the man a jacket']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['swap the bike for a motorcycle']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ["make the cat's nose black"]
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have a team of sled dogs pulling the snowboarder']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['edit some mountains in the background']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['put the zebras next to a river']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the piece of paper hanging on the wall a mirror']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['put an easter basket on the desk']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['what if the man was bald']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['what if he had a angry mouth?']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have there be a dolphin jumping out of the water']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['replace the baseball bat for a laser sword']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['switch to a robot wearing armor']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the cow smile']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the cow lift its leg up']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let there be an old greek monument']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['change the dog for a cat']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['change the background to a river']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['swap the cupcake with a piece of cake']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['turn the cell phone into a banana']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let the faucet be turned on']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have the person jump over a tennis ball']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have the person swing the racquet between his legs']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['place a bag on the court']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['add a cruise ship to the ocean']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow flowers']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let a rat sniff the broccoli']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['add a plate of meat']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['the ocean should have waves']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a rat']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the suitcase red']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['replace the truck with a bus']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['replace the american flag with a red flag']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let her bite the hot dog']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make her wear a baseball hat']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have a bird stand on the zebras head']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have the zebra bent over a hay pile']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['have a bucket hang off the fence']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let the zebra sit']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a fox']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the cat lick its nose']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let the mirror turn into a window']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the man not swing but hold the bat down towards the ground']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ["make the man's pants all white"]
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make it a black sheep']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['a dog should be near the sheep']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['what if there is flowers on the vase on the toilet?']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['change the green ball to blue']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['make the dog leaf']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['add a dog bowl']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let the player wear white socks']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['swap the motorcycle for a car']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['remove the tent and add a bonfire']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let the cat be white']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella be striped']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['remove the shoes']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['change the flag of the united states for that of england']
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ["add mickey's face"]
[2025-03-09 13:44:13 ViT-B/16] (vificlip.py 183): INFO ['add a rubber duck']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['take away the skateboarders arms']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['make the ramp cement']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a street']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['turn her hair white']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['give her a skirt to wear']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change the stop sign to a welcome sign']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let it be a bullet train']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a bird on the road']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change the color of the soccer ball']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['remove middle fruit and put a cat in place']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['put a robot tiger next to the bear']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let there be a crystal ball on the table']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have recessed lighting']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let there be a bedroom near the kitchen']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['what if he is holding a cup?']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a plane in the sky']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['remove the clouds']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change the boy to a girl']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['put sunglasses on the girl']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['it should be a notebook on the table']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a doctor']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['remove the tomatoes from one sandwich']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let there be a stuffed panda']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['remove the wooden frame']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let white animals stick their tongues out']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['remove the surfboards']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['have the instructor\'s jacket say "4" on it']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['have the instructor be wearing pink pants']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the zebra put its face up close to a tree']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['put a couch next to the window']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the man be angry']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the man be dressed in a dinner jacket']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change the tennis racket into a baseball bat']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change the hat to a cowboy hat']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['replace all the food with a big pizza']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change the frisbee into a ball']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a whale in the ocean']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a dog barking near shore']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the phone booth be red']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the red building be white']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a dog next to the car']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['have the man be wearing a kilt']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a giant wasp']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['let the person raise his arm']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['place a cat in the counter']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['remove the cloth from the chairs']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add some orange juice inside the blender']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['add a vodka bottle']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['change it for some shot glasses']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['he should be eating a watermelon']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['could he be in the forest?']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the elephant']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['give the zebra a single front leg']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ["open the zebra's mouth"]
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['make her outfit black']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the dog']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['make the frisbee blue']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['get rid of the spatula']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['make the cake vanilla']
[2025-03-09 13:44:14 ViT-B/16] (vificlip.py 183): INFO ['make the roses into tulips']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['place a red warning sign saying "stop"']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a beret']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the motorcycles and cars pink']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['put a hot air balloon in the background']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add a cotton candy machine']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['close her eyes']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['remove the person behind the woman']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the woman clap']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['put another freezer on the truck']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['open the door of the truck']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the people angry']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['can we have a blue airplane?']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['could it be a pond next to the airfield?']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the donut a cupcake']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['replace the coffee with beer']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['put a rat on the counter']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the dog howl']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the planters be made of cast stone']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the planters have fruit trees in it']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ["let's add a monitor on the wall"]
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['change the carrot into broccoli']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['change the clock to a tv']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['put a show about cats on the tv']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the two men fall']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add white flowers on the lawn']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the sky rain']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['change the double deck bus to a truck']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add a pedestrian']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['the boy should be holding a banana']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['can the man hold bananas too?']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['there should be no dolls in the room']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add a few balloons to the room']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['have there be trees in the background']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let a dog stand on its hind legs']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the table have no items on it']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the shelf be empty']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['replace the frisbee with a ball']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let it be a single sink']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the window show a view of skyscrapers']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let a cat lick its paw']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a ship']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['get rid of the framed pictures']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['and rum bottles']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the plate blue']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the fruits whole']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['have the cow wear a hat']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['put a computer on the kitchen']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['leave only one stool']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the sign show an address']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add a red flag above the sign']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add white geese in the sky']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['have the sun rise instead of set']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make two parasailers instead of one']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['make the ground a forest instead of a slope']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['swap the cats for a fox']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['fill the table with cakes']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['add water and flowers in the tub']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the floor be made of hardwood']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the man have legs up in air']
[2025-03-09 13:44:15 ViT-B/16] (vificlip.py 183): INFO ['let the man wear a helmet']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let there be a giant snowball next to the man']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['change the male player for a female']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['remove bananas and add grapes']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['turn the all street lights green']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put traffic cones in the street']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['change the fan into a chandelier']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let curtains be closed on the window']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the table have sofas near the dining table']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['have one of the children be blowing bubbles']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['remove the table and add an aquarium']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['place a penguin in the picture']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['change the bicycle to a blue bicycle']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['the lid of a toilet should be open']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put a vase of flowers in the sink']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['it should it be a window on the bathroom']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make it a slice of pizza instead of the sandwich']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['there should be some cutlery on the table']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['remove the guts in the tennis racket']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make a hand hold the racket']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let a flock of birds fly in the sky']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the stop light be a spear']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the street be flooded']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let a cop stand on the side']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['have there be a bottle behind the vegetables']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make one fruit have a face']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the fruit with a face']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['can it be just a woman and a child?']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['can you put a city on the background?']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put a car next to the child']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ["have there be a unicorn on the back of the woman's shirt"]
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['what if the man was standing?']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['remove the computer and add a coffee machine']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['remove one chair']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the baseball glove be red']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['add a sparrow']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the yellow hat be red']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['it should be a chocolate cake on the plate']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put a glass of juice next to the plate']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['can it be a red plate?']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['have a gorilla sit at the dinner table']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['replace the greens with onions']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['replace the fruit with more veggies']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put in different kinds of cheese instead of crackers']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the bed be wooden']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the tiled floor be made of plain granite']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make a cat jump onto a bed']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['add a cat falling out of a tree']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put a wedding cake on one of the tables']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['put a fountain in front of the restaurant']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make the stop sing an animal sign']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['add another cup of water']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make the plate empty']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['get rid of the bananas']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['leave only oranges']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['make the doll wear a hat']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['change the knife to a chainsaw']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['change the pizza into a cake']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['change the bowl of fruit into a plate of salad']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['let the cat have its eyes closed']
[2025-03-09 13:44:16 ViT-B/16] (vificlip.py 183): INFO ['add a woman inside the car']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['add luggage on top of the car']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['remove a giraffe']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella have stripes']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['let a bird fly nearby']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['let the cat sleep']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['awake the dog and give it brown eyes']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['let the dog yawn']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['put a face mask on one of the players']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ["put a helmet on the player's haed"]
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['add a dear on the grass']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['put a big rock next to the cow']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['can we have a pond next to the cart?']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['can we put a hand on the door?']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['put a drawing of a rat next to the hand']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['the door could be cracked']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a blue tank top']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ["change the woman's hair to blonde"]
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ["add flowers in the girl's hair"]
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['add binary code on the computer']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['it should be a tennis ball on the glove']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['the background should be a ocean']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['could it be two balls?']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['let the people sit down']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['remove the motorcyclist']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['turn the pizza into a croissant']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['change the orange into kiwi fruit']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['let it be a mushroom salad']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['make one of the shoes black']
[2025-03-09 13:44:17 ViT-B/16] (vificlip.py 183): INFO ['what if the man had a hat?']
[2025-03-09 13:47:39 ViT-B/16] (vificlip.py 232): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:47:41 ViT-B/16] (vificlip.py 235): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:47:41 ViT-B/16] (vificlip.py 252): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:47:41 ViT-B/16] (vificlip.py 276): INFO Total learnable items: 302
[2025-03-09 13:48:01 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['what if the vegetables are in a bowl?']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ["let's add a drawing of a flower to the fridge"]
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the sun shine']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['it could be a microwave next to the woman']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['can it be a boy not a girl?']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['could the woman hold a banana?']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the vehicle be replaced by a bicycle']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['a girl is eating cereal']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the woman drink wine']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add a bus station']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add people']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add an airplane']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['what if the boy was bald?']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let a forest be the background']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the player wear a red hat']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['change the toothpicks into candles']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the plate be made of glass']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the sandwich be vegan']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['give the girl a baseball bat instead of a racket']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['remove the tennis ball']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['give her a baseball cap']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['get rid of the racket']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['give her jean pants']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add a cyclist on the street']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['change the bus for a school bus']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add a dog walking in front of the guy']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['can it be a cake on the plate?']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['put a donut next to the cake']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['can we have a glass of soda next to the plate?']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the cat have a short tail']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['replace it with a black dog']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['remove one of its eyes']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['give it a hat']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the woman smile']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ["let's add a rat next to the pizza"]
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['change the hair color to pink']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['put a whale in the water']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['put a policeman in the intersection']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['turn the remote into a pizza']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['give the man glasses']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let the jam be changed to strawberry one']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add a turtle']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['change the wooden cabinetry to steel']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['change the wood floor to tiled floor']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['add soda cans on the counter']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['let there be pigs in the pen']
[2025-03-09 13:48:01 ViT-B/16] (vificlip.py 183): INFO ['remove the fence']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let a child point at the animals']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the horse eat a carrot without the bag']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let a penguin look at the horse']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the horse close its eyes']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the woman cry']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the woman have blonde hair']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the woman hold a cup']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the fruit be sliced bananas']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let a plate contain sliced bread']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the plates be on a wooden table']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['change the stuffed toys into rubber duckies']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the dogs sleep in a basket']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let a spider be in the basket']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['change the text on the parking meter to say "no"']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['have there be a digital display on the parking meters']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['give the bird a long tail']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['add flowers']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['have baby birds follow the large bird']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ["change the table's color to red"]
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ["let's give him a yellow shirt"]
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['change the swimsuit color to green']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the arabic writing be changed to chinese']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['add a car instead of motorcycles']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['edit the background by removing the museum and placing a castle']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['replace the stuffed animals with a pillow']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the monitor turn black']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['replace the donuts with fruits']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let a woman in a bridal gown stand near the cake']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let there be heart shaped balloons']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ["let's add a cat on the roof"]
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the fence be made of wood']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the cat wear a bow tie instead of a tie']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the cat have blue eyes']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the cat lay on a wooden floor instead of a carpet']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['remove the ball']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['remove the bat']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['remove the batter']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the woman kiss']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the woman make a heart sign with her hands']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the bowl have chocolate sauce']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['open the lid of a toilet']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['replace the chocolate with berries']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['add a lizard on the counter']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the plate contain ice cream']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['get rid of the cat']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['put a vase on top of the table']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['get rid of the vase on top of the table']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ["let's add a cowboy hat to the giraffe"]
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog in the grass"]
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let a cat be near the hydrant']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['let the hydrant be small and red']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a pickup truck']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['swap the kites with drones']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['turn the mountain in a waterfall']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['a parakeet should be sitting on the knit item']
[2025-03-09 13:48:02 ViT-B/16] (vificlip.py 183): INFO ['a cat should be watching the parakeet while sitting in a flower pot']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['the cat should have a hat on']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['make the apples green']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['get rid of the jar of cookies']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['make the cake a chocolate cake']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the man press the keyboard']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['what if the child was holding a bottle of peper?']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['what if there was a drawing of a bird on his shirt?']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['the car should be white']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put a red sign insted of the bike']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put a ball on the sidewalk']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['change the trees to palm trees']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['remove the people']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put a parking meter next to the bus']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put a penguin near the polar bears']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['change the clock tower to a bell tower']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the patch of flowers be daffodils']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['add a rocket in the sky']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the surfboard be green']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['remove the words']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['add a shark next to the surfboard']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['have a cruise ship pull into the harbor']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['add hot air balloons']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the kid sleep']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['give the person a bowl']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the older man have dark hair']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the ladies wear red dresses']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the older man wear a cowboy hat']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ["make the man's top blue"]
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['remove the frisbee']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['make all the grass green']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow letters']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['change the usa flag into a japanese flag']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let a pilot walk next to the plane']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the van turn black']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ["split the top layer so there's an extra one"]
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put bride and groom toppers on it']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['remove the frosting between layers']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put a tennis racket next to the bat']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['get rid of the baseball bat']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let there be a game show on tv']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let there be granite floor in the kitchen']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark wood']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['turn the frisbee into a soccer ball']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the dog have a newspaper in its mouth']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let there be potted plant']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['make the zebra a regular horse']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the blood orange be swapped with an apple']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['change the ski gear into a scuba gear']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the tree be conifers']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['add a polar bear']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the man cut pizza with a knife']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['make it a pepperoni pizza']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the man have a tattoo on his hand']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the bluebery cake be topped with chocolate syrup']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let the drink be replaced by a glass of milk']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['change the truck into a taxi']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['let a herd of sheep block the taxi']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['change the trees at the back into palm trees']
[2025-03-09 13:48:03 ViT-B/16] (vificlip.py 183): INFO ['put strawberry on the plate']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['leave nothing on top of the cheesecake']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['make the man ride a motorcycle instead of a bicycle']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['swap the surfboard for a skateboard']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let the couch be an expensive leather one']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let the window show a garden']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have wooden beams']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a battle tank']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let a man run towards the tank']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let there be an oak tree']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog next to the cows"]
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a cup of coffee']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['remove the salad on the side']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let a green towel be hung in the bathroom']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add cookies to the tray']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the bag of chips into a backpack']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['remove the playstation controller']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['remove one of the pizzas']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the toppings to pepperoni and cheese']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put a lion in the place of the donkey']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['turn the basin into a plastic pool']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let the ship be blue']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a cat']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a table in front']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['have there be a basket of fruit on the counter']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['take the objects off the dresser']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change kids to men']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a dog catching a ball']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a rainbow in the sky']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put popcorn in the plate']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ["make the dog's eyes closed"]
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put skis on the wheel']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put a wooden floor on the kitchen']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put a table on the kitchen']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put a microwave on the counter']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let the carpet be changed to wooden floor']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['an airplane is smoking from the cockpit']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['it should be just one cow']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['could it be a river on the background?']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a goat next to the cow']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the tea into cappuccino']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the sandwich to salad']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a bottle of sauce']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['make the plane further away']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['replace the cart with an upright one']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['replace the traffic meter with a pole']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['put a puppy in the cart']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['there should be a tree on the front']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['it should be a mountain in the background']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['the trash can should be blue']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['cover the bread with sauce and salad']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['add a glass of water']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the fork to a spoon']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['have a fly sit on the laptop']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['make the scarf multi-colored']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['make the woman smile']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ["make the woman's hair more straightened out"]
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['change the vegetables into broccoli']
[2025-03-09 13:48:04 ViT-B/16] (vificlip.py 183): INFO ['let the sandwiches be changed to risotto']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let the apples be changed to orange slices']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let water run from the faucet']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['remove the car']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['replace the sign with a stop sign']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['put a squirrel on top of the sign']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the woman hold a camera']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['give the woman another camera']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let the cup contain flowers']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let there be a bug on the wood']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the scooter into a skateboard']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let the tree have lush green leaves']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let the boy wear a superhero costume']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the washington monument with the statue of liberty']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['add flying eagles over the statue']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the recording devices to makeup']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the laptop into a makeup tray']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the wood desk a white table']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the flowers on the wallet to be white']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['have there be a bee on the wallet']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the cows']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['can we have mountains on the background?']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['put a horse insted of the goats']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let the elephant turn young']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['take the papers out the table']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the glass of water a to go cup']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the tables to a playland']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the red lights to green lights']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['add a truck on the street']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['remove the trees']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a stuffed action figure toy']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let a child play nearby']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['add a cat on the top of a counter']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the yellow lights to white lights']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['add a champagne bottle']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['remove that sink']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['the bed should be red']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['put a pile of shoes next to the bed']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['could we have a window next to the bed?']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the toilet pink']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['remove the apple']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['give the man a jacket']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['swap the bike for a motorcycle']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ["make the cat's nose black"]
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['have a team of sled dogs pulling the snowboarder']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['edit some mountains in the background']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['put the zebras next to a river']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the piece of paper hanging on the wall a mirror']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['put an easter basket on the desk']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['what if the man was bald']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['what if he had a angry mouth?']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['have there be a dolphin jumping out of the water']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['replace the baseball bat for a laser sword']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['switch to a robot wearing armor']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the cow smile']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['make the cow lift its leg up']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['let there be an old greek monument']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the dog for a cat']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['change the background to a river']
[2025-03-09 13:48:05 ViT-B/16] (vificlip.py 183): INFO ['swap the cupcake with a piece of cake']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['turn the cell phone into a banana']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the faucet be turned on']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['have the person jump over a tennis ball']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['have the person swing the racquet between his legs']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['place a bag on the court']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a cruise ship to the ocean']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow flowers']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let a rat sniff the broccoli']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a plate of meat']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['the ocean should have waves']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a rat']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make the suitcase red']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['replace the truck with a bus']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['replace the american flag with a red flag']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let her bite the hot dog']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make her wear a baseball hat']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['have a bird stand on the zebras head']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['have the zebra bent over a hay pile']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['have a bucket hang off the fence']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the zebra sit']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a fox']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make the cat lick its nose']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the mirror turn into a window']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make the man not swing but hold the bat down towards the ground']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ["make the man's pants all white"]
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make it a black sheep']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['a dog should be near the sheep']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['what if there is flowers on the vase on the toilet?']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the green ball to blue']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make the dog leaf']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a dog bowl']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the player wear white socks']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['swap the motorcycle for a car']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['remove the tent and add a bonfire']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the cat be white']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella be striped']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['remove the shoes']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the flag of the united states for that of england']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ["add mickey's face"]
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a rubber duck']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['take away the skateboarders arms']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['make the ramp cement']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a street']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['turn her hair white']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['give her a skirt to wear']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the stop sign to a welcome sign']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let it be a bullet train']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a bird on the road']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the color of the soccer ball']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['remove middle fruit and put a cat in place']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['put a robot tiger next to the bear']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let there be a crystal ball on the table']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have recessed lighting']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['let there be a bedroom near the kitchen']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['what if he is holding a cup?']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['add a plane in the sky']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['remove the clouds']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['change the boy to a girl']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['put sunglasses on the girl']
[2025-03-09 13:48:06 ViT-B/16] (vificlip.py 183): INFO ['it should be a notebook on the table']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a doctor']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['remove the tomatoes from one sandwich']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let there be a stuffed panda']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['remove the wooden frame']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let white animals stick their tongues out']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['remove the surfboards']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['have the instructor\'s jacket say "4" on it']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['have the instructor be wearing pink pants']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let the zebra put its face up close to a tree']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['put a couch next to the window']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let the man be angry']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let the man be dressed in a dinner jacket']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['change the tennis racket into a baseball bat']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['change the hat to a cowboy hat']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['replace all the food with a big pizza']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['change the frisbee into a ball']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a whale in the ocean']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a dog barking near shore']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let the phone booth be red']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let the red building be white']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a dog next to the car']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['have the man be wearing a kilt']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a giant wasp']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['let the person raise his arm']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['place a cat in the counter']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['remove the cloth from the chairs']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add some orange juice inside the blender']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a vodka bottle']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['change it for some shot glasses']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['he should be eating a watermelon']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['could he be in the forest?']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the elephant']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['give the zebra a single front leg']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ["open the zebra's mouth"]
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make her outfit black']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the dog']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the frisbee blue']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['get rid of the spatula']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the cake vanilla']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the roses into tulips']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['place a red warning sign saying "stop"']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a beret']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the motorcycles and cars pink']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['put a hot air balloon in the background']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['add a cotton candy machine']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['close her eyes']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['remove the person behind the woman']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the woman clap']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['put another freezer on the truck']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['open the door of the truck']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the people angry']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['can we have a blue airplane?']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['could it be a pond next to the airfield?']
[2025-03-09 13:48:07 ViT-B/16] (vificlip.py 183): INFO ['make the donut a cupcake']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['replace the coffee with beer']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['put a rat on the counter']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make the dog howl']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the planters be made of cast stone']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the planters have fruit trees in it']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ["let's add a monitor on the wall"]
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the carrot into broccoli']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the clock to a tv']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['put a show about cats on the tv']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make the two men fall']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['add white flowers on the lawn']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make the sky rain']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the double deck bus to a truck']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['add a pedestrian']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['the boy should be holding a banana']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['can the man hold bananas too?']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['there should be no dolls in the room']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['add a few balloons to the room']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['have there be trees in the background']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let a dog stand on its hind legs']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the table have no items on it']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the shelf be empty']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['replace the frisbee with a ball']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let it be a single sink']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the window show a view of skyscrapers']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let a cat lick its paw']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a ship']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['get rid of the framed pictures']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['and rum bottles']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make the plate blue']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make the fruits whole']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['have the cow wear a hat']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['put a computer on the kitchen']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['leave only one stool']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the sign show an address']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['add a red flag above the sign']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['add white geese in the sky']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['have the sun rise instead of set']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make two parasailers instead of one']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['make the ground a forest instead of a slope']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['swap the cats for a fox']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['fill the table with cakes']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['add water and flowers in the tub']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the floor be made of hardwood']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the man have legs up in air']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the man wear a helmet']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let there be a giant snowball next to the man']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the male player for a female']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['remove bananas and add grapes']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['turn the all street lights green']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['put traffic cones in the street']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the fan into a chandelier']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let curtains be closed on the window']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['let the table have sofas near the dining table']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['have one of the children be blowing bubbles']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['remove the table and add an aquarium']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['place a penguin in the picture']
[2025-03-09 13:48:08 ViT-B/16] (vificlip.py 183): INFO ['change the bicycle to a blue bicycle']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['the lid of a toilet should be open']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a vase of flowers in the sink']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['it should it be a window on the bathroom']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make it a slice of pizza instead of the sandwich']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['there should be some cutlery on the table']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['remove the guts in the tennis racket']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make a hand hold the racket']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let a flock of birds fly in the sky']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the stop light be a spear']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the street be flooded']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let a cop stand on the side']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['have there be a bottle behind the vegetables']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make one fruit have a face']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the fruit with a face']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['can it be just a woman and a child?']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['can you put a city on the background?']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a car next to the child']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ["have there be a unicorn on the back of the woman's shirt"]
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['what if the man was standing?']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['remove the computer and add a coffee machine']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['remove one chair']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the baseball glove be red']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['add a sparrow']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the yellow hat be red']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['it should be a chocolate cake on the plate']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a glass of juice next to the plate']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['can it be a red plate?']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['have a gorilla sit at the dinner table']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['replace the greens with onions']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['replace the fruit with more veggies']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put in different kinds of cheese instead of crackers']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the bed be wooden']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the tiled floor be made of plain granite']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make a cat jump onto a bed']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['add a cat falling out of a tree']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a wedding cake on one of the tables']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a fountain in front of the restaurant']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make the stop sing an animal sign']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['add another cup of water']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make the plate empty']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['get rid of the bananas']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['leave only oranges']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['make the doll wear a hat']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['change the knife to a chainsaw']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['change the pizza into a cake']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['change the bowl of fruit into a plate of salad']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the cat have its eyes closed']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['add a woman inside the car']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['add luggage on top of the car']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['remove a giraffe']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella have stripes']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let a bird fly nearby']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the cat sleep']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['awake the dog and give it brown eyes']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['let the dog yawn']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['put a face mask on one of the players']
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ["put a helmet on the player's haed"]
[2025-03-09 13:48:09 ViT-B/16] (vificlip.py 183): INFO ['add a dear on the grass']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['put a big rock next to the cow']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['can we have a pond next to the cart?']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['can we put a hand on the door?']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['put a drawing of a rat next to the hand']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['the door could be cracked']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a blue tank top']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ["change the woman's hair to blonde"]
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ["add flowers in the girl's hair"]
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['add binary code on the computer']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['it should be a tennis ball on the glove']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['the background should be a ocean']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['could it be two balls?']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['let the people sit down']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['remove the motorcyclist']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['turn the pizza into a croissant']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['change the orange into kiwi fruit']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['let it be a mushroom salad']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['make one of the shoes black']
[2025-03-09 13:48:10 ViT-B/16] (vificlip.py 183): INFO ['what if the man had a hat?']
[2025-03-09 13:48:11 ViT-B/16] (vificlip.py 232): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:48:12 ViT-B/16] (vificlip.py 235): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:48:12 ViT-B/16] (vificlip.py 252): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:48:12 ViT-B/16] (vificlip.py 276): INFO Total learnable items: 302
[2025-03-09 13:48:32 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['what if the vegetables are in a bowl?']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ["let's add a drawing of a flower to the fridge"]
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['let the sun shine']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['it could be a microwave next to the woman']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['can it be a boy not a girl?']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['could the woman hold a banana?']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['let the vehicle be replaced by a bicycle']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['a girl is eating cereal']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['let the woman drink wine']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['add a bus station']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['add people']
[2025-03-09 13:48:32 ViT-B/16] (vificlip.py 183): INFO ['add an airplane']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['what if the boy was bald?']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let a forest be the background']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the player wear a red hat']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the toothpicks into candles']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the plate be made of glass']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the sandwich be vegan']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['give the girl a baseball bat instead of a racket']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['remove the tennis ball']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['give her a baseball cap']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['get rid of the racket']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['give her jean pants']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['add a cyclist on the street']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the bus for a school bus']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['add a dog walking in front of the guy']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['can it be a cake on the plate?']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['put a donut next to the cake']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['can we have a glass of soda next to the plate?']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the cat have a short tail']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['replace it with a black dog']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['remove one of its eyes']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['give it a hat']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the woman smile']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ["let's add a rat next to the pizza"]
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the hair color to pink']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['put a whale in the water']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['put a policeman in the intersection']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['turn the remote into a pizza']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['give the man glasses']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the jam be changed to strawberry one']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['add a turtle']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the wooden cabinetry to steel']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the wood floor to tiled floor']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['add soda cans on the counter']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let there be pigs in the pen']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['remove the fence']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let a child point at the animals']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the horse eat a carrot without the bag']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let a penguin look at the horse']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the horse close its eyes']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the woman cry']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the woman have blonde hair']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the woman hold a cup']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the fruit be sliced bananas']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let a plate contain sliced bread']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the plates be on a wooden table']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the stuffed toys into rubber duckies']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the dogs sleep in a basket']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let a spider be in the basket']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the text on the parking meter to say "no"']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['have there be a digital display on the parking meters']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['give the bird a long tail']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['add flowers']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['have baby birds follow the large bird']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ["change the table's color to red"]
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ["let's give him a yellow shirt"]
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['change the swimsuit color to green']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['let the arabic writing be changed to chinese']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['add a car instead of motorcycles']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['edit the background by removing the museum and placing a castle']
[2025-03-09 13:48:33 ViT-B/16] (vificlip.py 183): INFO ['replace the stuffed animals with a pillow']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the monitor turn black']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['replace the donuts with fruits']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let a woman in a bridal gown stand near the cake']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let there be heart shaped balloons']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ["let's add a cat on the roof"]
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the fence be made of wood']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the cat wear a bow tie instead of a tie']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the cat have blue eyes']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the cat lay on a wooden floor instead of a carpet']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['remove the ball']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['remove the bat']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['remove the batter']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the woman kiss']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the woman make a heart sign with her hands']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the bowl have chocolate sauce']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['open the lid of a toilet']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['replace the chocolate with berries']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['add a lizard on the counter']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the plate contain ice cream']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['get rid of the cat']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['put a vase on top of the table']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['get rid of the vase on top of the table']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ["let's add a cowboy hat to the giraffe"]
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog in the grass"]
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let a cat be near the hydrant']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the hydrant be small and red']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a pickup truck']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['swap the kites with drones']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['turn the mountain in a waterfall']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['a parakeet should be sitting on the knit item']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['a cat should be watching the parakeet while sitting in a flower pot']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['the cat should have a hat on']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['make the apples green']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['get rid of the jar of cookies']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['make the cake a chocolate cake']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the man press the keyboard']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['what if the child was holding a bottle of peper?']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['what if there was a drawing of a bird on his shirt?']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['the car should be white']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['put a red sign insted of the bike']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['put a ball on the sidewalk']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['change the trees to palm trees']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['remove the people']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['put a parking meter next to the bus']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['put a penguin near the polar bears']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['change the clock tower to a bell tower']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the patch of flowers be daffodils']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['add a rocket in the sky']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the surfboard be green']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['remove the words']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['add a shark next to the surfboard']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['have a cruise ship pull into the harbor']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['add hot air balloons']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the kid sleep']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['give the person a bowl']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the older man have dark hair']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the ladies wear red dresses']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['let the older man wear a cowboy hat']
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ["make the man's top blue"]
[2025-03-09 13:48:34 ViT-B/16] (vificlip.py 183): INFO ['remove the frisbee']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['make all the grass green']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow letters']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the usa flag into a japanese flag']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let a pilot walk next to the plane']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the van turn black']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ["split the top layer so there's an extra one"]
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['put bride and groom toppers on it']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['remove the frosting between layers']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['put a tennis racket next to the bat']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['get rid of the baseball bat']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let there be a game show on tv']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let there be granite floor in the kitchen']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark wood']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['turn the frisbee into a soccer ball']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the dog have a newspaper in its mouth']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let there be potted plant']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['make the zebra a regular horse']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the blood orange be swapped with an apple']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the ski gear into a scuba gear']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the tree be conifers']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add a polar bear']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the man cut pizza with a knife']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['make it a pepperoni pizza']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the man have a tattoo on his hand']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the bluebery cake be topped with chocolate syrup']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the drink be replaced by a glass of milk']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the truck into a taxi']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let a herd of sheep block the taxi']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the trees at the back into palm trees']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['put strawberry on the plate']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['leave nothing on top of the cheesecake']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['make the man ride a motorcycle instead of a bicycle']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['swap the surfboard for a skateboard']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the couch be an expensive leather one']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the window show a garden']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have wooden beams']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a battle tank']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let a man run towards the tank']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let there be an oak tree']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog next to the cows"]
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add a cup of coffee']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['remove the salad on the side']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let a green towel be hung in the bathroom']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add cookies to the tray']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the bag of chips into a backpack']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['remove the playstation controller']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['remove one of the pizzas']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change the toppings to pepperoni and cheese']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['put a lion in the place of the donkey']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['turn the basin into a plastic pool']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['let the ship be blue']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add a cat']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add a table in front']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['have there be a basket of fruit on the counter']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['take the objects off the dresser']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['change kids to men']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add a dog catching a ball']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['add a rainbow in the sky']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ['put popcorn in the plate']
[2025-03-09 13:48:35 ViT-B/16] (vificlip.py 183): INFO ["make the dog's eyes closed"]
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put skis on the wheel']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a wooden floor on the kitchen']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a table on the kitchen']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a microwave on the counter']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the carpet be changed to wooden floor']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['an airplane is smoking from the cockpit']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['it should be just one cow']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['could it be a river on the background?']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['add a goat next to the cow']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the tea into cappuccino']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the sandwich to salad']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['add a bottle of sauce']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['make the plane further away']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['replace the cart with an upright one']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['replace the traffic meter with a pole']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a puppy in the cart']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['there should be a tree on the front']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['it should be a mountain in the background']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['the trash can should be blue']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['cover the bread with sauce and salad']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['add a glass of water']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the fork to a spoon']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['have a fly sit on the laptop']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['make the scarf multi-colored']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['make the woman smile']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ["make the woman's hair more straightened out"]
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the vegetables into broccoli']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the sandwiches be changed to risotto']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the apples be changed to orange slices']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let water run from the faucet']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['remove the car']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['replace the sign with a stop sign']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a squirrel on top of the sign']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['make the woman hold a camera']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['give the woman another camera']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the cup contain flowers']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let there be a bug on the wood']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the scooter into a skateboard']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the tree have lush green leaves']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the boy wear a superhero costume']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the washington monument with the statue of liberty']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['add flying eagles over the statue']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the recording devices to makeup']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the laptop into a makeup tray']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['make the wood desk a white table']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the flowers on the wallet to be white']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['have there be a bee on the wallet']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the cows']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['can we have mountains on the background?']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['put a horse insted of the goats']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let the elephant turn young']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['take the papers out the table']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['make the glass of water a to go cup']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the tables to a playland']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the red lights to green lights']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['add a truck on the street']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['remove the trees']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a stuffed action figure toy']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['let a child play nearby']
[2025-03-09 13:48:36 ViT-B/16] (vificlip.py 183): INFO ['add a cat on the top of a counter']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['change the yellow lights to white lights']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['add a champagne bottle']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['remove that sink']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['the bed should be red']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['put a pile of shoes next to the bed']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['could we have a window next to the bed?']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the toilet pink']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['remove the apple']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['give the man a jacket']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['swap the bike for a motorcycle']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ["make the cat's nose black"]
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have a team of sled dogs pulling the snowboarder']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['edit some mountains in the background']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['put the zebras next to a river']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the piece of paper hanging on the wall a mirror']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['put an easter basket on the desk']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['what if the man was bald']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['what if he had a angry mouth?']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have there be a dolphin jumping out of the water']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['replace the baseball bat for a laser sword']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['switch to a robot wearing armor']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the cow smile']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the cow lift its leg up']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['let there be an old greek monument']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['change the dog for a cat']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['change the background to a river']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['swap the cupcake with a piece of cake']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['turn the cell phone into a banana']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['let the faucet be turned on']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have the person jump over a tennis ball']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have the person swing the racquet between his legs']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['place a bag on the court']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['add a cruise ship to the ocean']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow flowers']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['let a rat sniff the broccoli']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['add a plate of meat']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['the ocean should have waves']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a rat']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the suitcase red']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['replace the truck with a bus']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['replace the american flag with a red flag']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['let her bite the hot dog']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make her wear a baseball hat']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have a bird stand on the zebras head']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have the zebra bent over a hay pile']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['have a bucket hang off the fence']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['let the zebra sit']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a fox']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the cat lick its nose']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['let the mirror turn into a window']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the man not swing but hold the bat down towards the ground']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ["make the man's pants all white"]
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make it a black sheep']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['a dog should be near the sheep']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['what if there is flowers on the vase on the toilet?']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['change the green ball to blue']
[2025-03-09 13:48:37 ViT-B/16] (vificlip.py 183): INFO ['make the dog leaf']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a dog bowl']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the player wear white socks']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['swap the motorcycle for a car']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the tent and add a bonfire']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the cat be white']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella be striped']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the shoes']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the flag of the united states for that of england']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ["add mickey's face"]
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a rubber duck']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['take away the skateboarders arms']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['make the ramp cement']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a street']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['turn her hair white']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['give her a skirt to wear']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the stop sign to a welcome sign']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let it be a bullet train']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a bird on the road']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the color of the soccer ball']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove middle fruit and put a cat in place']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['put a robot tiger next to the bear']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let there be a crystal ball on the table']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have recessed lighting']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let there be a bedroom near the kitchen']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['what if he is holding a cup?']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a plane in the sky']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the clouds']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the boy to a girl']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['put sunglasses on the girl']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['it should be a notebook on the table']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a doctor']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the tomatoes from one sandwich']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let there be a stuffed panda']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the wooden frame']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let white animals stick their tongues out']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the surfboards']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['have the instructor\'s jacket say "4" on it']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['have the instructor be wearing pink pants']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the zebra put its face up close to a tree']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['put a couch next to the window']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the man be angry']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the man be dressed in a dinner jacket']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the tennis racket into a baseball bat']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the hat to a cowboy hat']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['replace all the food with a big pizza']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change the frisbee into a ball']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a whale in the ocean']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a dog barking near shore']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the phone booth be red']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the red building be white']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a dog next to the car']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['have the man be wearing a kilt']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a giant wasp']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['let the person raise his arm']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['place a cat in the counter']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['remove the cloth from the chairs']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add some orange juice inside the blender']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['add a vodka bottle']
[2025-03-09 13:48:38 ViT-B/16] (vificlip.py 183): INFO ['change it for some shot glasses']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['he should be eating a watermelon']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['could he be in the forest?']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the elephant']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['give the zebra a single front leg']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ["open the zebra's mouth"]
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make her outfit black']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the dog']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the frisbee blue']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['get rid of the spatula']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the cake vanilla']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the roses into tulips']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['place a red warning sign saying "stop"']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a beret']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the motorcycles and cars pink']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put a hot air balloon in the background']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['add a cotton candy machine']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['close her eyes']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['remove the person behind the woman']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the woman clap']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put another freezer on the truck']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['open the door of the truck']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the people angry']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['can we have a blue airplane?']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['could it be a pond next to the airfield?']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the donut a cupcake']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['replace the coffee with beer']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put a rat on the counter']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the dog howl']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let the planters be made of cast stone']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let the planters have fruit trees in it']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ["let's add a monitor on the wall"]
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['change the carrot into broccoli']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['change the clock to a tv']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put a show about cats on the tv']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the two men fall']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['add white flowers on the lawn']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the sky rain']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['change the double deck bus to a truck']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['add a pedestrian']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['the boy should be holding a banana']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['can the man hold bananas too?']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['there should be no dolls in the room']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['add a few balloons to the room']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['have there be trees in the background']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let a dog stand on its hind legs']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let the table have no items on it']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let the shelf be empty']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['replace the frisbee with a ball']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let it be a single sink']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let the window show a view of skyscrapers']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['let a cat lick its paw']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a ship']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['get rid of the framed pictures']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['and rum bottles']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the plate blue']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['make the fruits whole']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['have the cow wear a hat']
[2025-03-09 13:48:39 ViT-B/16] (vificlip.py 183): INFO ['put a computer on the kitchen']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['leave only one stool']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the sign show an address']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['add a red flag above the sign']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['add white geese in the sky']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['have the sun rise instead of set']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['make two parasailers instead of one']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['make the ground a forest instead of a slope']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['swap the cats for a fox']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['fill the table with cakes']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['add water and flowers in the tub']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the floor be made of hardwood']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the man have legs up in air']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the man wear a helmet']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let there be a giant snowball next to the man']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['change the male player for a female']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['remove bananas and add grapes']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['turn the all street lights green']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['put traffic cones in the street']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['change the fan into a chandelier']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let curtains be closed on the window']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the table have sofas near the dining table']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['have one of the children be blowing bubbles']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['remove the table and add an aquarium']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['place a penguin in the picture']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['change the bicycle to a blue bicycle']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['the lid of a toilet should be open']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['put a vase of flowers in the sink']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['it should it be a window on the bathroom']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['make it a slice of pizza instead of the sandwich']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['there should be some cutlery on the table']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['remove the guts in the tennis racket']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['make a hand hold the racket']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let a flock of birds fly in the sky']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the stop light be a spear']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the street be flooded']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let a cop stand on the side']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['have there be a bottle behind the vegetables']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['make one fruit have a face']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the fruit with a face']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['can it be just a woman and a child?']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['can you put a city on the background?']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['put a car next to the child']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ["have there be a unicorn on the back of the woman's shirt"]
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['what if the man was standing?']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['remove the computer and add a coffee machine']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['remove one chair']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the baseball glove be red']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['add a sparrow']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the yellow hat be red']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['it should be a chocolate cake on the plate']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['put a glass of juice next to the plate']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['can it be a red plate?']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['have a gorilla sit at the dinner table']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['replace the greens with onions']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['replace the fruit with more veggies']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['put in different kinds of cheese instead of crackers']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the bed be wooden']
[2025-03-09 13:48:40 ViT-B/16] (vificlip.py 183): INFO ['let the tiled floor be made of plain granite']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['make a cat jump onto a bed']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['add a cat falling out of a tree']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['put a wedding cake on one of the tables']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['put a fountain in front of the restaurant']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['make the stop sing an animal sign']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['add another cup of water']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['make the plate empty']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['get rid of the bananas']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['leave only oranges']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['make the doll wear a hat']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['change the knife to a chainsaw']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['change the pizza into a cake']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['change the bowl of fruit into a plate of salad']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let the cat have its eyes closed']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['add a woman inside the car']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['add luggage on top of the car']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['remove a giraffe']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella have stripes']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let a bird fly nearby']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let the cat sleep']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['awake the dog and give it brown eyes']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let the dog yawn']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['put a face mask on one of the players']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ["put a helmet on the player's haed"]
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['add a dear on the grass']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['put a big rock next to the cow']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['can we have a pond next to the cart?']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['can we put a hand on the door?']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['put a drawing of a rat next to the hand']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['the door could be cracked']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a blue tank top']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ["change the woman's hair to blonde"]
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ["add flowers in the girl's hair"]
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['add binary code on the computer']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['it should be a tennis ball on the glove']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['the background should be a ocean']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['could it be two balls?']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let the people sit down']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['remove the motorcyclist']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['turn the pizza into a croissant']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['change the orange into kiwi fruit']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['let it be a mushroom salad']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['make one of the shoes black']
[2025-03-09 13:48:41 ViT-B/16] (vificlip.py 183): INFO ['what if the man had a hat?']
[2025-03-09 13:48:45 ViT-B/16] (vificlip.py 232): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:48:46 ViT-B/16] (vificlip.py 235): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:48:46 ViT-B/16] (vificlip.py 252): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:48:46 ViT-B/16] (vificlip.py 276): INFO Total learnable items: 302
[2025-03-09 13:49:06 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['what if the vegetables are in a bowl?']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ["let's add a drawing of a flower to the fridge"]
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['let the sun shine']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['it could be a microwave next to the woman']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['can it be a boy not a girl?']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['could the woman hold a banana?']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['let the vehicle be replaced by a bicycle']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['a girl is eating cereal']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['let the woman drink wine']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['add a bus station']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['add people']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['add an airplane']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['what if the boy was bald?']
[2025-03-09 13:49:06 ViT-B/16] (vificlip.py 183): INFO ['let a forest be the background']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the player wear a red hat']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the toothpicks into candles']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the plate be made of glass']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the sandwich be vegan']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['give the girl a baseball bat instead of a racket']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['remove the tennis ball']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['give her a baseball cap']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['get rid of the racket']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['give her jean pants']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['add a cyclist on the street']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the bus for a school bus']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['add a dog walking in front of the guy']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['can it be a cake on the plate?']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['put a donut next to the cake']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['can we have a glass of soda next to the plate?']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the cat have a short tail']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['replace it with a black dog']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['remove one of its eyes']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['give it a hat']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the woman smile']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ["let's add a rat next to the pizza"]
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the hair color to pink']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['put a whale in the water']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['put a policeman in the intersection']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['turn the remote into a pizza']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['give the man glasses']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the jam be changed to strawberry one']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['add a turtle']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the wooden cabinetry to steel']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the wood floor to tiled floor']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['add soda cans on the counter']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let there be pigs in the pen']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['remove the fence']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let a child point at the animals']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the horse eat a carrot without the bag']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let a penguin look at the horse']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the horse close its eyes']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the woman cry']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the woman have blonde hair']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the woman hold a cup']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the fruit be sliced bananas']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let a plate contain sliced bread']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the plates be on a wooden table']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the stuffed toys into rubber duckies']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the dogs sleep in a basket']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let a spider be in the basket']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the text on the parking meter to say "no"']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['have there be a digital display on the parking meters']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['give the bird a long tail']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['add flowers']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['have baby birds follow the large bird']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ["change the table's color to red"]
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ["let's give him a yellow shirt"]
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['change the swimsuit color to green']
[2025-03-09 13:49:07 ViT-B/16] (vificlip.py 183): INFO ['let the arabic writing be changed to chinese']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['add a car instead of motorcycles']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['edit the background by removing the museum and placing a castle']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['replace the stuffed animals with a pillow']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the monitor turn black']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['replace the donuts with fruits']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let a woman in a bridal gown stand near the cake']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let there be heart shaped balloons']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ["let's add a cat on the roof"]
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the fence be made of wood']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the cat wear a bow tie instead of a tie']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the cat have blue eyes']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the cat lay on a wooden floor instead of a carpet']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['remove the ball']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['remove the bat']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['remove the batter']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the woman kiss']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the woman make a heart sign with her hands']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the bowl have chocolate sauce']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['open the lid of a toilet']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['replace the chocolate with berries']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['add a lizard on the counter']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the plate contain ice cream']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['get rid of the cat']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['put a vase on top of the table']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['get rid of the vase on top of the table']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ["let's add a cowboy hat to the giraffe"]
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog in the grass"]
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let a cat be near the hydrant']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the hydrant be small and red']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a pickup truck']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['swap the kites with drones']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['turn the mountain in a waterfall']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['a parakeet should be sitting on the knit item']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['a cat should be watching the parakeet while sitting in a flower pot']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['the cat should have a hat on']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['make the apples green']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['get rid of the jar of cookies']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['make the cake a chocolate cake']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the man press the keyboard']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['what if the child was holding a bottle of peper?']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['what if there was a drawing of a bird on his shirt?']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['the car should be white']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['put a red sign insted of the bike']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['put a ball on the sidewalk']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['change the trees to palm trees']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['remove the people']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['put a parking meter next to the bus']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['put a penguin near the polar bears']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['change the clock tower to a bell tower']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the patch of flowers be daffodils']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['add a rocket in the sky']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the surfboard be green']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['remove the words']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['add a shark next to the surfboard']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['have a cruise ship pull into the harbor']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['add hot air balloons']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['let the kid sleep']
[2025-03-09 13:49:08 ViT-B/16] (vificlip.py 183): INFO ['give the person a bowl']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the older man have dark hair']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the ladies wear red dresses']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the older man wear a cowboy hat']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ["make the man's top blue"]
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['remove the frisbee']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['make all the grass green']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow letters']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the usa flag into a japanese flag']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let a pilot walk next to the plane']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the van turn black']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ["split the top layer so there's an extra one"]
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['put bride and groom toppers on it']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['remove the frosting between layers']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['put a tennis racket next to the bat']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['get rid of the baseball bat']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let there be a game show on tv']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let there be granite floor in the kitchen']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark wood']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['turn the frisbee into a soccer ball']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the dog have a newspaper in its mouth']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let there be potted plant']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['make the zebra a regular horse']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the blood orange be swapped with an apple']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the ski gear into a scuba gear']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the tree be conifers']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['add a polar bear']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the man cut pizza with a knife']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['make it a pepperoni pizza']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the man have a tattoo on his hand']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the bluebery cake be topped with chocolate syrup']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the drink be replaced by a glass of milk']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the truck into a taxi']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let a herd of sheep block the taxi']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the trees at the back into palm trees']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['put strawberry on the plate']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['leave nothing on top of the cheesecake']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['make the man ride a motorcycle instead of a bicycle']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['swap the surfboard for a skateboard']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the couch be an expensive leather one']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the window show a garden']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have wooden beams']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a battle tank']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let a man run towards the tank']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let there be an oak tree']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog next to the cows"]
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['add a cup of coffee']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['remove the salad on the side']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let a green towel be hung in the bathroom']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['add cookies to the tray']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the bag of chips into a backpack']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['remove the playstation controller']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['remove one of the pizzas']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['change the toppings to pepperoni and cheese']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['put a lion in the place of the donkey']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['turn the basin into a plastic pool']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['let the ship be blue']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['add a cat']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['add a table in front']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['have there be a basket of fruit on the counter']
[2025-03-09 13:49:09 ViT-B/16] (vificlip.py 183): INFO ['take the objects off the dresser']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change kids to men']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['add a dog catching a ball']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['add a rainbow in the sky']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put popcorn in the plate']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ["make the dog's eyes closed"]
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put skis on the wheel']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a wooden floor on the kitchen']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a table on the kitchen']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a microwave on the counter']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the carpet be changed to wooden floor']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['an airplane is smoking from the cockpit']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['it should be just one cow']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['could it be a river on the background?']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['add a goat next to the cow']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the tea into cappuccino']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the sandwich to salad']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['add a bottle of sauce']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['make the plane further away']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['replace the cart with an upright one']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['replace the traffic meter with a pole']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a puppy in the cart']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['there should be a tree on the front']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['it should be a mountain in the background']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['the trash can should be blue']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['cover the bread with sauce and salad']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['add a glass of water']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the fork to a spoon']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['have a fly sit on the laptop']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['make the scarf multi-colored']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['make the woman smile']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ["make the woman's hair more straightened out"]
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the vegetables into broccoli']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the sandwiches be changed to risotto']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the apples be changed to orange slices']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let water run from the faucet']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['remove the car']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['replace the sign with a stop sign']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a squirrel on top of the sign']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['make the woman hold a camera']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['give the woman another camera']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the cup contain flowers']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let there be a bug on the wood']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the scooter into a skateboard']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the tree have lush green leaves']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the boy wear a superhero costume']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the washington monument with the statue of liberty']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['add flying eagles over the statue']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the recording devices to makeup']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the laptop into a makeup tray']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['make the wood desk a white table']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['change the flowers on the wallet to be white']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['have there be a bee on the wallet']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the cows']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['can we have mountains on the background?']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['put a horse insted of the goats']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['let the elephant turn young']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['take the papers out the table']
[2025-03-09 13:49:10 ViT-B/16] (vificlip.py 183): INFO ['make the glass of water a to go cup']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the tables to a playland']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the red lights to green lights']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['add a truck on the street']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['remove the trees']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a stuffed action figure toy']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let a child play nearby']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['add a cat on the top of a counter']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the yellow lights to white lights']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['add a champagne bottle']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['remove that sink']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['the bed should be red']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['put a pile of shoes next to the bed']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['could we have a window next to the bed?']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the toilet pink']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['remove the apple']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['give the man a jacket']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['swap the bike for a motorcycle']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ["make the cat's nose black"]
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have a team of sled dogs pulling the snowboarder']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['edit some mountains in the background']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['put the zebras next to a river']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the piece of paper hanging on the wall a mirror']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['put an easter basket on the desk']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['what if the man was bald']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['what if he had a angry mouth?']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have there be a dolphin jumping out of the water']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['replace the baseball bat for a laser sword']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['switch to a robot wearing armor']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the cow smile']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the cow lift its leg up']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let there be an old greek monument']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the dog for a cat']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the background to a river']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['swap the cupcake with a piece of cake']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['turn the cell phone into a banana']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let the faucet be turned on']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have the person jump over a tennis ball']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have the person swing the racquet between his legs']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['place a bag on the court']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['add a cruise ship to the ocean']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow flowers']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let a rat sniff the broccoli']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['add a plate of meat']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['the ocean should have waves']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a rat']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the suitcase red']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['replace the truck with a bus']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['replace the american flag with a red flag']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let her bite the hot dog']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make her wear a baseball hat']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have a bird stand on the zebras head']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have the zebra bent over a hay pile']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['have a bucket hang off the fence']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let the zebra sit']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a fox']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the cat lick its nose']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['let the mirror turn into a window']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make the man not swing but hold the bat down towards the ground']
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ["make the man's pants all white"]
[2025-03-09 13:49:11 ViT-B/16] (vificlip.py 183): INFO ['make it a black sheep']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['a dog should be near the sheep']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['what if there is flowers on the vase on the toilet?']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the green ball to blue']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['make the dog leaf']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a dog bowl']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the player wear white socks']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['swap the motorcycle for a car']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove the tent and add a bonfire']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the cat be white']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella be striped']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove the shoes']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the flag of the united states for that of england']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ["add mickey's face"]
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a rubber duck']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['take away the skateboarders arms']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['make the ramp cement']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a street']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['turn her hair white']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['give her a skirt to wear']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the stop sign to a welcome sign']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let it be a bullet train']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a bird on the road']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the color of the soccer ball']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove middle fruit and put a cat in place']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['put a robot tiger next to the bear']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let there be a crystal ball on the table']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have recessed lighting']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let there be a bedroom near the kitchen']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['what if he is holding a cup?']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a plane in the sky']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove the clouds']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the boy to a girl']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['put sunglasses on the girl']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['it should be a notebook on the table']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a doctor']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove the tomatoes from one sandwich']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let there be a stuffed panda']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove the wooden frame']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let white animals stick their tongues out']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['remove the surfboards']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['have the instructor\'s jacket say "4" on it']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['have the instructor be wearing pink pants']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the zebra put its face up close to a tree']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['put a couch next to the window']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the man be angry']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the man be dressed in a dinner jacket']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the tennis racket into a baseball bat']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the hat to a cowboy hat']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['replace all the food with a big pizza']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['change the frisbee into a ball']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a whale in the ocean']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a dog barking near shore']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the phone booth be red']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the red building be white']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a dog next to the car']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['have the man be wearing a kilt']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['add a giant wasp']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['let the person raise his arm']
[2025-03-09 13:49:12 ViT-B/16] (vificlip.py 183): INFO ['place a cat in the counter']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['remove the cloth from the chairs']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['add some orange juice inside the blender']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['add a vodka bottle']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['change it for some shot glasses']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['he should be eating a watermelon']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['could he be in the forest?']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the elephant']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['give the zebra a single front leg']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ["open the zebra's mouth"]
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make her outfit black']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the dog']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the frisbee blue']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['get rid of the spatula']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the cake vanilla']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the roses into tulips']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['place a red warning sign saying "stop"']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a beret']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the motorcycles and cars pink']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['put a hot air balloon in the background']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['add a cotton candy machine']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['close her eyes']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['remove the person behind the woman']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the woman clap']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['put another freezer on the truck']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['open the door of the truck']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the people angry']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['can we have a blue airplane?']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['could it be a pond next to the airfield?']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the donut a cupcake']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['replace the coffee with beer']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['put a rat on the counter']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the dog howl']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let the planters be made of cast stone']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let the planters have fruit trees in it']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ["let's add a monitor on the wall"]
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['change the carrot into broccoli']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['change the clock to a tv']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['put a show about cats on the tv']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the two men fall']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['add white flowers on the lawn']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['make the sky rain']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['change the double deck bus to a truck']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['add a pedestrian']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['the boy should be holding a banana']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['can the man hold bananas too?']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['there should be no dolls in the room']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['add a few balloons to the room']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['have there be trees in the background']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let a dog stand on its hind legs']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let the table have no items on it']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let the shelf be empty']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['replace the frisbee with a ball']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let it be a single sink']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let the window show a view of skyscrapers']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['let a cat lick its paw']
[2025-03-09 13:49:13 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a ship']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['get rid of the framed pictures']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['and rum bottles']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make the plate blue']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make the fruits whole']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['have the cow wear a hat']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['put a computer on the kitchen']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['leave only one stool']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the sign show an address']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['add a red flag above the sign']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['add white geese in the sky']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['have the sun rise instead of set']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make two parasailers instead of one']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make the ground a forest instead of a slope']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['swap the cats for a fox']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['fill the table with cakes']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['add water and flowers in the tub']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the floor be made of hardwood']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the man have legs up in air']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the man wear a helmet']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let there be a giant snowball next to the man']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['change the male player for a female']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['remove bananas and add grapes']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['turn the all street lights green']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['put traffic cones in the street']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['change the fan into a chandelier']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let curtains be closed on the window']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the table have sofas near the dining table']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['have one of the children be blowing bubbles']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['remove the table and add an aquarium']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['place a penguin in the picture']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['change the bicycle to a blue bicycle']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['the lid of a toilet should be open']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['put a vase of flowers in the sink']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['it should it be a window on the bathroom']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make it a slice of pizza instead of the sandwich']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['there should be some cutlery on the table']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['remove the guts in the tennis racket']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make a hand hold the racket']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let a flock of birds fly in the sky']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the stop light be a spear']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the street be flooded']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let a cop stand on the side']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['have there be a bottle behind the vegetables']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['make one fruit have a face']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the fruit with a face']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['can it be just a woman and a child?']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['can you put a city on the background?']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['put a car next to the child']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ["have there be a unicorn on the back of the woman's shirt"]
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['what if the man was standing?']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['remove the computer and add a coffee machine']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['remove one chair']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the baseball glove be red']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['add a sparrow']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['let the yellow hat be red']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['it should be a chocolate cake on the plate']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['put a glass of juice next to the plate']
[2025-03-09 13:49:14 ViT-B/16] (vificlip.py 183): INFO ['can it be a red plate?']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['have a gorilla sit at the dinner table']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['replace the greens with onions']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['replace the fruit with more veggies']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['put in different kinds of cheese instead of crackers']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the bed be wooden']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the tiled floor be made of plain granite']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['make a cat jump onto a bed']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['add a cat falling out of a tree']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['put a wedding cake on one of the tables']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['put a fountain in front of the restaurant']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['make the stop sing an animal sign']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['add another cup of water']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['make the plate empty']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['get rid of the bananas']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['leave only oranges']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['make the doll wear a hat']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['change the knife to a chainsaw']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['change the pizza into a cake']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['change the bowl of fruit into a plate of salad']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the cat have its eyes closed']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['add a woman inside the car']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['add luggage on top of the car']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['remove a giraffe']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella have stripes']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let a bird fly nearby']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the cat sleep']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['awake the dog and give it brown eyes']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the dog yawn']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['put a face mask on one of the players']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ["put a helmet on the player's haed"]
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['add a dear on the grass']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['put a big rock next to the cow']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['can we have a pond next to the cart?']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['can we put a hand on the door?']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['put a drawing of a rat next to the hand']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['the door could be cracked']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a blue tank top']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ["change the woman's hair to blonde"]
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ["add flowers in the girl's hair"]
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['add binary code on the computer']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['it should be a tennis ball on the glove']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['the background should be a ocean']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['could it be two balls?']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let the people sit down']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['remove the motorcyclist']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['turn the pizza into a croissant']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['change the orange into kiwi fruit']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['let it be a mushroom salad']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['make one of the shoes black']
[2025-03-09 13:49:15 ViT-B/16] (vificlip.py 183): INFO ['what if the man had a hat?']
[2025-03-09 13:49:33 ViT-B/16] (vificlip.py 232): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-09 13:49:34 ViT-B/16] (vificlip.py 235): INFO Building ViFi-CLIP CLIP
[2025-03-09 13:49:34 ViT-B/16] (vificlip.py 252): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-09 13:49:34 ViT-B/16] (vificlip.py 276): INFO Total learnable items: 302
[2025-03-09 13:49:54 ViT-B/16] (3050147269.py 27): INFO resume model: _IncompatibleKeys(missing_keys=['clip_model.positional_embedding', 'clip_model.text_projection', 'clip_model.logit_scale', 'clip_model.visual.class_embedding', 'clip_model.visual.positional_embedding', 'clip_model.visual.proj', 'clip_model.visual.conv1.weight', 'clip_model.visual.ln_pre.weight', 'clip_model.visual.ln_pre.bias', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_1.weight', 'clip_model.visual.transformer.resblocks.0.ln_1.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.0.ln_2.weight', 'clip_model.visual.transformer.resblocks.0.ln_2.bias', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_1.weight', 'clip_model.visual.transformer.resblocks.1.ln_1.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.1.ln_2.weight', 'clip_model.visual.transformer.resblocks.1.ln_2.bias', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_1.weight', 'clip_model.visual.transformer.resblocks.2.ln_1.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.2.ln_2.weight', 'clip_model.visual.transformer.resblocks.2.ln_2.bias', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_1.weight', 'clip_model.visual.transformer.resblocks.3.ln_1.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.3.ln_2.weight', 'clip_model.visual.transformer.resblocks.3.ln_2.bias', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_1.weight', 'clip_model.visual.transformer.resblocks.4.ln_1.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.4.ln_2.weight', 'clip_model.visual.transformer.resblocks.4.ln_2.bias', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_1.weight', 'clip_model.visual.transformer.resblocks.5.ln_1.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.5.ln_2.weight', 'clip_model.visual.transformer.resblocks.5.ln_2.bias', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_1.weight', 'clip_model.visual.transformer.resblocks.6.ln_1.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.6.ln_2.weight', 'clip_model.visual.transformer.resblocks.6.ln_2.bias', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_1.weight', 'clip_model.visual.transformer.resblocks.7.ln_1.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.7.ln_2.weight', 'clip_model.visual.transformer.resblocks.7.ln_2.bias', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_1.weight', 'clip_model.visual.transformer.resblocks.8.ln_1.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.8.ln_2.weight', 'clip_model.visual.transformer.resblocks.8.ln_2.bias', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_1.weight', 'clip_model.visual.transformer.resblocks.9.ln_1.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.9.ln_2.weight', 'clip_model.visual.transformer.resblocks.9.ln_2.bias', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_1.weight', 'clip_model.visual.transformer.resblocks.10.ln_1.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.10.ln_2.weight', 'clip_model.visual.transformer.resblocks.10.ln_2.bias', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.visual.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.visual.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_1.weight', 'clip_model.visual.transformer.resblocks.11.ln_1.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.visual.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.visual.transformer.resblocks.11.ln_2.weight', 'clip_model.visual.transformer.resblocks.11.ln_2.bias', 'clip_model.visual.ln_post.weight', 'clip_model.visual.ln_post.bias', 'clip_model.transformer.resblocks.0.attn.in_proj_weight', 'clip_model.transformer.resblocks.0.attn.in_proj_bias', 'clip_model.transformer.resblocks.0.attn.out_proj.weight', 'clip_model.transformer.resblocks.0.attn.out_proj.bias', 'clip_model.transformer.resblocks.0.ln_1.weight', 'clip_model.transformer.resblocks.0.ln_1.bias', 'clip_model.transformer.resblocks.0.mlp.c_fc.weight', 'clip_model.transformer.resblocks.0.mlp.c_fc.bias', 'clip_model.transformer.resblocks.0.mlp.c_proj.weight', 'clip_model.transformer.resblocks.0.mlp.c_proj.bias', 'clip_model.transformer.resblocks.0.ln_2.weight', 'clip_model.transformer.resblocks.0.ln_2.bias', 'clip_model.transformer.resblocks.1.attn.in_proj_weight', 'clip_model.transformer.resblocks.1.attn.in_proj_bias', 'clip_model.transformer.resblocks.1.attn.out_proj.weight', 'clip_model.transformer.resblocks.1.attn.out_proj.bias', 'clip_model.transformer.resblocks.1.ln_1.weight', 'clip_model.transformer.resblocks.1.ln_1.bias', 'clip_model.transformer.resblocks.1.mlp.c_fc.weight', 'clip_model.transformer.resblocks.1.mlp.c_fc.bias', 'clip_model.transformer.resblocks.1.mlp.c_proj.weight', 'clip_model.transformer.resblocks.1.mlp.c_proj.bias', 'clip_model.transformer.resblocks.1.ln_2.weight', 'clip_model.transformer.resblocks.1.ln_2.bias', 'clip_model.transformer.resblocks.2.attn.in_proj_weight', 'clip_model.transformer.resblocks.2.attn.in_proj_bias', 'clip_model.transformer.resblocks.2.attn.out_proj.weight', 'clip_model.transformer.resblocks.2.attn.out_proj.bias', 'clip_model.transformer.resblocks.2.ln_1.weight', 'clip_model.transformer.resblocks.2.ln_1.bias', 'clip_model.transformer.resblocks.2.mlp.c_fc.weight', 'clip_model.transformer.resblocks.2.mlp.c_fc.bias', 'clip_model.transformer.resblocks.2.mlp.c_proj.weight', 'clip_model.transformer.resblocks.2.mlp.c_proj.bias', 'clip_model.transformer.resblocks.2.ln_2.weight', 'clip_model.transformer.resblocks.2.ln_2.bias', 'clip_model.transformer.resblocks.3.attn.in_proj_weight', 'clip_model.transformer.resblocks.3.attn.in_proj_bias', 'clip_model.transformer.resblocks.3.attn.out_proj.weight', 'clip_model.transformer.resblocks.3.attn.out_proj.bias', 'clip_model.transformer.resblocks.3.ln_1.weight', 'clip_model.transformer.resblocks.3.ln_1.bias', 'clip_model.transformer.resblocks.3.mlp.c_fc.weight', 'clip_model.transformer.resblocks.3.mlp.c_fc.bias', 'clip_model.transformer.resblocks.3.mlp.c_proj.weight', 'clip_model.transformer.resblocks.3.mlp.c_proj.bias', 'clip_model.transformer.resblocks.3.ln_2.weight', 'clip_model.transformer.resblocks.3.ln_2.bias', 'clip_model.transformer.resblocks.4.attn.in_proj_weight', 'clip_model.transformer.resblocks.4.attn.in_proj_bias', 'clip_model.transformer.resblocks.4.attn.out_proj.weight', 'clip_model.transformer.resblocks.4.attn.out_proj.bias', 'clip_model.transformer.resblocks.4.ln_1.weight', 'clip_model.transformer.resblocks.4.ln_1.bias', 'clip_model.transformer.resblocks.4.mlp.c_fc.weight', 'clip_model.transformer.resblocks.4.mlp.c_fc.bias', 'clip_model.transformer.resblocks.4.mlp.c_proj.weight', 'clip_model.transformer.resblocks.4.mlp.c_proj.bias', 'clip_model.transformer.resblocks.4.ln_2.weight', 'clip_model.transformer.resblocks.4.ln_2.bias', 'clip_model.transformer.resblocks.5.attn.in_proj_weight', 'clip_model.transformer.resblocks.5.attn.in_proj_bias', 'clip_model.transformer.resblocks.5.attn.out_proj.weight', 'clip_model.transformer.resblocks.5.attn.out_proj.bias', 'clip_model.transformer.resblocks.5.ln_1.weight', 'clip_model.transformer.resblocks.5.ln_1.bias', 'clip_model.transformer.resblocks.5.mlp.c_fc.weight', 'clip_model.transformer.resblocks.5.mlp.c_fc.bias', 'clip_model.transformer.resblocks.5.mlp.c_proj.weight', 'clip_model.transformer.resblocks.5.mlp.c_proj.bias', 'clip_model.transformer.resblocks.5.ln_2.weight', 'clip_model.transformer.resblocks.5.ln_2.bias', 'clip_model.transformer.resblocks.6.attn.in_proj_weight', 'clip_model.transformer.resblocks.6.attn.in_proj_bias', 'clip_model.transformer.resblocks.6.attn.out_proj.weight', 'clip_model.transformer.resblocks.6.attn.out_proj.bias', 'clip_model.transformer.resblocks.6.ln_1.weight', 'clip_model.transformer.resblocks.6.ln_1.bias', 'clip_model.transformer.resblocks.6.mlp.c_fc.weight', 'clip_model.transformer.resblocks.6.mlp.c_fc.bias', 'clip_model.transformer.resblocks.6.mlp.c_proj.weight', 'clip_model.transformer.resblocks.6.mlp.c_proj.bias', 'clip_model.transformer.resblocks.6.ln_2.weight', 'clip_model.transformer.resblocks.6.ln_2.bias', 'clip_model.transformer.resblocks.7.attn.in_proj_weight', 'clip_model.transformer.resblocks.7.attn.in_proj_bias', 'clip_model.transformer.resblocks.7.attn.out_proj.weight', 'clip_model.transformer.resblocks.7.attn.out_proj.bias', 'clip_model.transformer.resblocks.7.ln_1.weight', 'clip_model.transformer.resblocks.7.ln_1.bias', 'clip_model.transformer.resblocks.7.mlp.c_fc.weight', 'clip_model.transformer.resblocks.7.mlp.c_fc.bias', 'clip_model.transformer.resblocks.7.mlp.c_proj.weight', 'clip_model.transformer.resblocks.7.mlp.c_proj.bias', 'clip_model.transformer.resblocks.7.ln_2.weight', 'clip_model.transformer.resblocks.7.ln_2.bias', 'clip_model.transformer.resblocks.8.attn.in_proj_weight', 'clip_model.transformer.resblocks.8.attn.in_proj_bias', 'clip_model.transformer.resblocks.8.attn.out_proj.weight', 'clip_model.transformer.resblocks.8.attn.out_proj.bias', 'clip_model.transformer.resblocks.8.ln_1.weight', 'clip_model.transformer.resblocks.8.ln_1.bias', 'clip_model.transformer.resblocks.8.mlp.c_fc.weight', 'clip_model.transformer.resblocks.8.mlp.c_fc.bias', 'clip_model.transformer.resblocks.8.mlp.c_proj.weight', 'clip_model.transformer.resblocks.8.mlp.c_proj.bias', 'clip_model.transformer.resblocks.8.ln_2.weight', 'clip_model.transformer.resblocks.8.ln_2.bias', 'clip_model.transformer.resblocks.9.attn.in_proj_weight', 'clip_model.transformer.resblocks.9.attn.in_proj_bias', 'clip_model.transformer.resblocks.9.attn.out_proj.weight', 'clip_model.transformer.resblocks.9.attn.out_proj.bias', 'clip_model.transformer.resblocks.9.ln_1.weight', 'clip_model.transformer.resblocks.9.ln_1.bias', 'clip_model.transformer.resblocks.9.mlp.c_fc.weight', 'clip_model.transformer.resblocks.9.mlp.c_fc.bias', 'clip_model.transformer.resblocks.9.mlp.c_proj.weight', 'clip_model.transformer.resblocks.9.mlp.c_proj.bias', 'clip_model.transformer.resblocks.9.ln_2.weight', 'clip_model.transformer.resblocks.9.ln_2.bias', 'clip_model.transformer.resblocks.10.attn.in_proj_weight', 'clip_model.transformer.resblocks.10.attn.in_proj_bias', 'clip_model.transformer.resblocks.10.attn.out_proj.weight', 'clip_model.transformer.resblocks.10.attn.out_proj.bias', 'clip_model.transformer.resblocks.10.ln_1.weight', 'clip_model.transformer.resblocks.10.ln_1.bias', 'clip_model.transformer.resblocks.10.mlp.c_fc.weight', 'clip_model.transformer.resblocks.10.mlp.c_fc.bias', 'clip_model.transformer.resblocks.10.mlp.c_proj.weight', 'clip_model.transformer.resblocks.10.mlp.c_proj.bias', 'clip_model.transformer.resblocks.10.ln_2.weight', 'clip_model.transformer.resblocks.10.ln_2.bias', 'clip_model.transformer.resblocks.11.attn.in_proj_weight', 'clip_model.transformer.resblocks.11.attn.in_proj_bias', 'clip_model.transformer.resblocks.11.attn.out_proj.weight', 'clip_model.transformer.resblocks.11.attn.out_proj.bias', 'clip_model.transformer.resblocks.11.ln_1.weight', 'clip_model.transformer.resblocks.11.ln_1.bias', 'clip_model.transformer.resblocks.11.mlp.c_fc.weight', 'clip_model.transformer.resblocks.11.mlp.c_fc.bias', 'clip_model.transformer.resblocks.11.mlp.c_proj.weight', 'clip_model.transformer.resblocks.11.mlp.c_proj.bias', 'clip_model.transformer.resblocks.11.ln_2.weight', 'clip_model.transformer.resblocks.11.ln_2.bias', 'clip_model.token_embedding.weight', 'clip_model.ln_final.weight', 'clip_model.ln_final.bias'], unexpected_keys=[])
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['what if the vegetables are in a bowl?']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ["let's add a drawing of a flower to the fridge"]
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['let the sun shine']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['it could be a microwave next to the woman']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['can it be a boy not a girl?']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['could the woman hold a banana?']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['let the vehicle be replaced by a bicycle']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['a girl is eating cereal']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['let the woman drink wine']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['add a bus station']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['add people']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['add an airplane']
[2025-03-09 13:49:54 ViT-B/16] (vificlip.py 183): INFO ['what if the boy was bald?']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let a forest be the background']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the player wear a red hat']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the toothpicks into candles']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the plate be made of glass']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the sandwich be vegan']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['give the girl a baseball bat instead of a racket']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['remove the tennis ball']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['give her a baseball cap']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['get rid of the racket']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['give her jean pants']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['add a cyclist on the street']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the bus for a school bus']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['add a dog walking in front of the guy']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['can it be a cake on the plate?']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['put a donut next to the cake']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['can we have a glass of soda next to the plate?']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the cat have a short tail']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['replace it with a black dog']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['remove one of its eyes']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['give it a hat']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the woman smile']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ["let's add a rat next to the pizza"]
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the hair color to pink']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['put a whale in the water']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['put a policeman in the intersection']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['turn the remote into a pizza']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['give the man glasses']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the jam be changed to strawberry one']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['add a turtle']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the wooden cabinetry to steel']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the wood floor to tiled floor']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['add soda cans on the counter']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let there be pigs in the pen']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['remove the fence']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let a child point at the animals']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the horse eat a carrot without the bag']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let a penguin look at the horse']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the horse close its eyes']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the woman cry']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the woman have blonde hair']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the woman hold a cup']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the fruit be sliced bananas']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let a plate contain sliced bread']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the plates be on a wooden table']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the stuffed toys into rubber duckies']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the dogs sleep in a basket']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let a spider be in the basket']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the text on the parking meter to say "no"']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['have there be a digital display on the parking meters']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['give the bird a long tail']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['add flowers']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['have baby birds follow the large bird']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ["change the table's color to red"]
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ["let's give him a yellow shirt"]
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['change the swimsuit color to green']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the arabic writing be changed to chinese']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['add a car instead of motorcycles']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['edit the background by removing the museum and placing a castle']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['replace the stuffed animals with a pillow']
[2025-03-09 13:49:55 ViT-B/16] (vificlip.py 183): INFO ['let the monitor turn black']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['replace the donuts with fruits']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let a woman in a bridal gown stand near the cake']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let there be heart shaped balloons']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ["let's add a cat on the roof"]
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the fence be made of wood']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the cat wear a bow tie instead of a tie']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the cat have blue eyes']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the cat lay on a wooden floor instead of a carpet']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the ball']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the bat']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the batter']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the woman kiss']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the woman make a heart sign with her hands']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the bowl have chocolate sauce']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['open the lid of a toilet']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['replace the chocolate with berries']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['add a lizard on the counter']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the plate contain ice cream']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['get rid of the cat']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['put a vase on top of the table']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['get rid of the vase on top of the table']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ["let's add a cowboy hat to the giraffe"]
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog in the grass"]
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let a cat be near the hydrant']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the hydrant be small and red']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a pickup truck']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['swap the kites with drones']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['turn the mountain in a waterfall']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['a parakeet should be sitting on the knit item']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['a cat should be watching the parakeet while sitting in a flower pot']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['the cat should have a hat on']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['make the apples green']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['get rid of the jar of cookies']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['make the cake a chocolate cake']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the man press the keyboard']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['what if the child was holding a bottle of peper?']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['what if there was a drawing of a bird on his shirt?']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['the car should be white']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['put a red sign insted of the bike']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['put a ball on the sidewalk']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['change the trees to palm trees']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the people']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['put a parking meter next to the bus']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['put a penguin near the polar bears']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['change the clock tower to a bell tower']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the patch of flowers be daffodils']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['add a rocket in the sky']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the surfboard be green']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the words']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['add a shark next to the surfboard']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['have a cruise ship pull into the harbor']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['add hot air balloons']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the kid sleep']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['give the person a bowl']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the older man have dark hair']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the ladies wear red dresses']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['let the older man wear a cowboy hat']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ["make the man's top blue"]
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the frisbee']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['make all the grass green']
[2025-03-09 13:49:56 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow letters']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the usa flag into a japanese flag']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let a pilot walk next to the plane']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the van turn black']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ["split the top layer so there's an extra one"]
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['put bride and groom toppers on it']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['remove the frosting between layers']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['put a tennis racket next to the bat']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['get rid of the baseball bat']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let there be a game show on tv']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let there be granite floor in the kitchen']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the cabinets be made of dark wood']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['turn the frisbee into a soccer ball']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the dog have a newspaper in its mouth']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let there be potted plant']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['make the zebra a regular horse']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the blood orange be swapped with an apple']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the ski gear into a scuba gear']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the tree be conifers']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add a polar bear']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the man cut pizza with a knife']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['make it a pepperoni pizza']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the man have a tattoo on his hand']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the bluebery cake be topped with chocolate syrup']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the drink be replaced by a glass of milk']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the truck into a taxi']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let a herd of sheep block the taxi']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the trees at the back into palm trees']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['put strawberry on the plate']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['leave nothing on top of the cheesecake']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['make the man ride a motorcycle instead of a bicycle']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['swap the surfboard for a skateboard']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the couch be an expensive leather one']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the window show a garden']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have wooden beams']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the fire truck into a battle tank']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let a man run towards the tank']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let there be an oak tree']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ["let's add a dog next to the cows"]
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add a cup of coffee']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['remove the salad on the side']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let a green towel be hung in the bathroom']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add cookies to the tray']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the bag of chips into a backpack']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['remove the playstation controller']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['remove one of the pizzas']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change the toppings to pepperoni and cheese']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['put a lion in the place of the donkey']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['turn the basin into a plastic pool']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['let the ship be blue']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add a cat']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add a table in front']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['have there be a basket of fruit on the counter']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['take the objects off the dresser']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['change kids to men']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add a dog catching a ball']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['add a rainbow in the sky']
[2025-03-09 13:49:57 ViT-B/16] (vificlip.py 183): INFO ['put popcorn in the plate']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ["make the dog's eyes closed"]
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put skis on the wheel']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a wooden floor on the kitchen']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a table on the kitchen']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a microwave on the counter']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the carpet be changed to wooden floor']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['an airplane is smoking from the cockpit']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['it should be just one cow']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['could it be a river on the background?']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['add a goat next to the cow']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the tea into cappuccino']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the sandwich to salad']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['add a bottle of sauce']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['make the plane further away']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['replace the cart with an upright one']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['replace the traffic meter with a pole']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a puppy in the cart']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['there should be a tree on the front']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['it should be a mountain in the background']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['the trash can should be blue']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['cover the bread with sauce and salad']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['add a glass of water']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the fork to a spoon']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['have a fly sit on the laptop']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['make the scarf multi-colored']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['make the woman smile']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ["make the woman's hair more straightened out"]
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the vegetables into broccoli']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the sandwiches be changed to risotto']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the apples be changed to orange slices']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let water run from the faucet']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['remove the car']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['replace the sign with a stop sign']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a squirrel on top of the sign']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['make the woman hold a camera']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['give the woman another camera']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the cup contain flowers']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let there be a bug on the wood']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the scooter into a skateboard']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the tree have lush green leaves']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the boy wear a superhero costume']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the washington monument with the statue of liberty']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['add flying eagles over the statue']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the recording devices to makeup']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the laptop into a makeup tray']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['make the wood desk a white table']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the flowers on the wallet to be white']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['have there be a bee on the wallet']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the cows']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['can we have mountains on the background?']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['put a horse insted of the goats']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['let the elephant turn young']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['take the papers out the table']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['make the glass of water a to go cup']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the tables to a playland']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the red lights to green lights']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['add a truck on the street']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['remove the trees']
[2025-03-09 13:49:58 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a stuffed action figure toy']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let a child play nearby']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['add a cat on the top of a counter']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['change the yellow lights to white lights']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['add a champagne bottle']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['remove that sink']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['the bed should be red']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['put a pile of shoes next to the bed']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['could we have a window next to the bed?']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the toilet pink']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['remove the apple']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['give the man a jacket']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['swap the bike for a motorcycle']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ["make the cat's nose black"]
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have a team of sled dogs pulling the snowboarder']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['edit some mountains in the background']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['put the zebras next to a river']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the piece of paper hanging on the wall a mirror']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['put an easter basket on the desk']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['what if the man was bald']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['what if he had a angry mouth?']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have there be a dolphin jumping out of the water']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['replace the baseball bat for a laser sword']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['switch to a robot wearing armor']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the cow smile']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the cow lift its leg up']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let there be an old greek monument']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['change the dog for a cat']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['change the background to a river']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['swap the cupcake with a piece of cake']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['turn the cell phone into a banana']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let the faucet be turned on']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have the person jump over a tennis ball']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have the person swing the racquet between his legs']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['place a bag on the court']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['add a cruise ship to the ocean']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['remove the yellow flowers']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let a rat sniff the broccoli']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['add a plate of meat']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['the ocean should have waves']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a rat']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the suitcase red']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['replace the truck with a bus']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['replace the american flag with a red flag']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let her bite the hot dog']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make her wear a baseball hat']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have a bird stand on the zebras head']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have the zebra bent over a hay pile']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['have a bucket hang off the fence']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let the zebra sit']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['change the cat to a fox']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the cat lick its nose']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['let the mirror turn into a window']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the man not swing but hold the bat down towards the ground']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ["make the man's pants all white"]
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make it a black sheep']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['a dog should be near the sheep']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['what if there is flowers on the vase on the toilet?']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['change the green ball to blue']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['make the dog leaf']
[2025-03-09 13:49:59 ViT-B/16] (vificlip.py 183): INFO ['add a dog bowl']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the player wear white socks']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['swap the motorcycle for a car']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the tent and add a bonfire']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the cat be white']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella be striped']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the shoes']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the flag of the united states for that of england']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ["add mickey's face"]
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a rubber duck']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['take away the skateboarders arms']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['make the ramp cement']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a street']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['turn her hair white']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['give her a skirt to wear']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the stop sign to a welcome sign']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let it be a bullet train']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a bird on the road']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the color of the soccer ball']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove middle fruit and put a cat in place']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['put a robot tiger next to the bear']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let there be a crystal ball on the table']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the ceiling have recessed lighting']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let there be a bedroom near the kitchen']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['what if he is holding a cup?']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a plane in the sky']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the clouds']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the boy to a girl']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['put sunglasses on the girl']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['it should be a notebook on the table']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a doctor']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the tomatoes from one sandwich']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let there be a stuffed panda']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the wooden frame']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let white animals stick their tongues out']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the surfboards']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['have the instructor\'s jacket say "4" on it']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['have the instructor be wearing pink pants']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the zebra put its face up close to a tree']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['put a couch next to the window']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the man be angry']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the man be dressed in a dinner jacket']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the tennis racket into a baseball bat']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the hat to a cowboy hat']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['replace all the food with a big pizza']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change the frisbee into a ball']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a whale in the ocean']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a dog barking near shore']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the phone booth be red']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the red building be white']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a dog next to the car']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['have the man be wearing a kilt']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a giant wasp']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['let the person raise his arm']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['place a cat in the counter']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['remove the cloth from the chairs']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add some orange juice inside the blender']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['add a vodka bottle']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['change it for some shot glasses']
[2025-03-09 13:50:00 ViT-B/16] (vificlip.py 183): INFO ['he should be eating a watermelon']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['could he be in the forest?']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put a pond next to the elephant']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['give the zebra a single front leg']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ["open the zebra's mouth"]
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make her outfit black']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the dog']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the frisbee blue']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['get rid of the spatula']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the cake vanilla']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the roses into tulips']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['place a red warning sign saying "stop"']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a beret']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the motorcycles and cars pink']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put a hot air balloon in the background']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['add a cotton candy machine']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['close her eyes']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['remove the person behind the woman']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the woman clap']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put another freezer on the truck']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['open the door of the truck']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the people angry']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['can we have a blue airplane?']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['could it be a pond next to the airfield?']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the donut a cupcake']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['replace the coffee with beer']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put a rat on the counter']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the dog howl']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let the planters be made of cast stone']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let the planters have fruit trees in it']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ["let's add a monitor on the wall"]
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['change the carrot into broccoli']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['change the clock to a tv']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put a show about cats on the tv']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the two men fall']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['add white flowers on the lawn']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the sky rain']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['change the double deck bus to a truck']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['add a pedestrian']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['the boy should be holding a banana']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['can the man hold bananas too?']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['there should be no dolls in the room']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['add a few balloons to the room']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['have there be trees in the background']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let a dog stand on its hind legs']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let the table have no items on it']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let the shelf be empty']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['replace the frisbee with a ball']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let it be a single sink']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let the window show a view of skyscrapers']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let a cat lick its paw']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['change the teddy bear into a ship']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['get rid of the framed pictures']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['and rum bottles']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the plate blue']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['make the fruits whole']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['have the cow wear a hat']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['put a computer on the kitchen']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['leave only one stool']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['let the sign show an address']
[2025-03-09 13:50:01 ViT-B/16] (vificlip.py 183): INFO ['add a red flag above the sign']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['add white geese in the sky']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['have the sun rise instead of set']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['make two parasailers instead of one']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['make the ground a forest instead of a slope']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['swap the cats for a fox']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['fill the table with cakes']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['add water and flowers in the tub']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the floor be made of hardwood']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the man have legs up in air']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the man wear a helmet']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let there be a giant snowball next to the man']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['change the male player for a female']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['remove bananas and add grapes']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['turn the all street lights green']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put traffic cones in the street']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['change the fan into a chandelier']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let curtains be closed on the window']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the table have sofas near the dining table']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['have one of the children be blowing bubbles']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['remove the table and add an aquarium']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['place a penguin in the picture']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['change the bicycle to a blue bicycle']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['the lid of a toilet should be open']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put a vase of flowers in the sink']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['it should it be a window on the bathroom']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['make it a slice of pizza instead of the sandwich']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['there should be some cutlery on the table']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['remove the guts in the tennis racket']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['make a hand hold the racket']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let a flock of birds fly in the sky']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the stop light be a spear']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the street be flooded']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let a cop stand on the side']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['have there be a bottle behind the vegetables']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['make one fruit have a face']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put a party hat on the fruit with a face']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['can it be just a woman and a child?']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['can you put a city on the background?']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put a car next to the child']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ["have there be a unicorn on the back of the woman's shirt"]
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['what if the man was standing?']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['remove the computer and add a coffee machine']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['remove one chair']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the baseball glove be red']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['add a sparrow']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the yellow hat be red']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['it should be a chocolate cake on the plate']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put a glass of juice next to the plate']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['can it be a red plate?']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['have a gorilla sit at the dinner table']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['replace the greens with onions']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['replace the fruit with more veggies']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put in different kinds of cheese instead of crackers']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the bed be wooden']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['let the tiled floor be made of plain granite']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['make a cat jump onto a bed']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['add a cat falling out of a tree']
[2025-03-09 13:50:02 ViT-B/16] (vificlip.py 183): INFO ['put a wedding cake on one of the tables']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['put a fountain in front of the restaurant']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['make the stop sing an animal sign']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['add another cup of water']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['make the plate empty']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['get rid of the bananas']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['leave only oranges']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['make the doll wear a hat']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['change the knife to a chainsaw']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['change the pizza into a cake']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['change the bowl of fruit into a plate of salad']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let the cat have its eyes closed']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['add a woman inside the car']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['add luggage on top of the car']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['remove a giraffe']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let the umbrella have stripes']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let a bird fly nearby']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let the cat sleep']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['awake the dog and give it brown eyes']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let the dog yawn']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['put a face mask on one of the players']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ["put a helmet on the player's haed"]
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['add a dear on the grass']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['put a big rock next to the cow']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['can we have a pond next to the cart?']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['can we put a hand on the door?']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['put a drawing of a rat next to the hand']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['the door could be cracked']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['have the woman be wearing a blue tank top']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ["change the woman's hair to blonde"]
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ["add flowers in the girl's hair"]
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['add binary code on the computer']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['it should be a tennis ball on the glove']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['the background should be a ocean']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['could it be two balls?']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let the people sit down']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['remove the motorcyclist']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['turn the pizza into a croissant']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['change the orange into kiwi fruit']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['let it be a mushroom salad']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['make one of the shoes black']
[2025-03-09 13:50:03 ViT-B/16] (vificlip.py 183): INFO ['what if the man had a hat?']
