{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fea83d3-1964-47cb-97ec-d0df9210cb64",
   "metadata": {},
   "source": [
    "# Classification of Prompts using GPT-4o\n",
    "\n",
    "This script uses **GPT-4o** to classify prompts in the **validation split**, allowing for a more refined correlation analysis. The classification may reveal that **CLIP** has a better understanding of certain prompt categories.\n",
    "\n",
    "Analysis of results can be found in the file `correlation_vifi_human.ipynb`.\n",
    "\n",
    "## Classification Categories\n",
    "\n",
    "1. **Semantic Category**  \n",
    "   - Object Addition  \n",
    "   - Object Removal  \n",
    "   - Object Replacement  \n",
    "   - Color Changes  \n",
    "   - Attribute Changes  \n",
    "   - Scene Changes  \n",
    "   - Other  \n",
    "\n",
    "2. **Instruction Type**  \n",
    "   - Imperative (Command)  \n",
    "   - Interrogative (Question)  \n",
    "\n",
    "3. **Visual Impact**  \n",
    "   - Subtle Edit  \n",
    "   - Moderate Edit  \n",
    "   - Drastic Edit  \n",
    "\n",
    "4. **Object Type**  \n",
    "   - Animals  \n",
    "   - People  \n",
    "   - Furniture/Objects  \n",
    "   - Vehicles  \n",
    "   - Food  \n",
    "   - Background/Scene  \n",
    "   - Other  \n",
    "\n",
    "\n",
    "----\n",
    "The prompt was written according to OpenAI's [prompt instructions](https://platform.openai.com/docs/guides/vision), specifically for visual content.\n",
    "\n",
    "The OpenAI API Key needs to be specified in the `.env` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbebc2-e76f-4f41-9430-216cedeb5947",
   "metadata": {},
   "source": [
    "Install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0356230-765f-4c3a-aaa1-2e82ca7cd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python -q\n",
    "!pip install torchvision -q\n",
    "!pip install torchmetrics -q\n",
    "!pip install torchmetrics[image] -q\n",
    "!pip install \"torchmetrics[image]\" -q\n",
    "!pip install torch-fidelity -q\n",
    "!pip install numpy -q\n",
    "!pip install torchmetrics -q\n",
    "!pip install torch -q\n",
    "!pip install openai -q\n",
    "!pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e050ddfb-cf6e-4711-83aa-6037de5c1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import base64\n",
    "import requests\n",
    "import openai\n",
    "import os\n",
    "import ast\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23f6d80-7479-461b-84f4-f61197aa0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# load_dotenv(dotenv_path=\"/home/jovyan/BA/Github/thesis-edit-evaluation/.env\")\n",
    "\n",
    "# specify model\n",
    "MODEL = \"gpt-4o-2024-08-06\"\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feebf359-6159-401c-8b96-35e3c441a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You will be given instructions of examples within instruction-guided Image Editing. I want you to classify them based on four different aspects:\n",
    "\n",
    "1. Semantic Category (What does the instruction do?): Choose from: Object Addition, Object Removal, Object Replacement, Color Changes, Attribute Changes, Scene Changes, Other.\n",
    "\n",
    "2. Instruction Type (How is it phrased?): Choose from: Imperative (Command), Interrogative (Question).\n",
    "\n",
    "3. Visual Impact (How drastic is the change?): Choose from: Subtle Edit, Moderate Edit, Drastic Edit.\n",
    "\n",
    "4. Object Type (What is being modified?): Choose from: Animals, People, Furniture/Objects, Vehicles, Food, Background/Scene, Other.\n",
    "\n",
    "Provide the classification as a list of categories, such as [\"Object Addition\", \"Imperative\", \"Subtle Edit\", \"Animals\"] - nothing else.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_user_prompt(instruction):\n",
    "    return f\"Classify the instruction: {instruction}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87c091b2-e200-4034-9b4f-5ce637c3feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "\n",
    "def call_api(img_original, img_edited, instruction):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,  # \"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": get_user_prompt(instruction)},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img_original}\"},\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_edited}\"},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d56aaf4-ec8e-48f1-9037-be3b1a4a40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image):\n",
    "    if isinstance(image, Image.Image):\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")  # oder ein anderes unterst√ºtztes Format\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a PIL Image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79f55143-54f4-4c8f-b4cd-c3f851916a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the regex pattern to extract id and turn from the output filename\n",
    "pattern = r\"(\\d+)-output(\\d+)\"\n",
    "\n",
    "with open(\n",
    "    \"/home/jovyan/BA/Github/thesis-edit-evaluation/experiments/edit_turns.json\"\n",
    ") as f:\n",
    "    turns = json.load(f)\n",
    "\n",
    "dev = pd.read_csv(\"annotations_mean_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c8d1a9d-dad2-4721-adf6-5eaebe2a13d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn</th>\n",
       "      <th>vificlip_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360871</td>\n",
       "      <td>1</td>\n",
       "      <td>25.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360871</td>\n",
       "      <td>2</td>\n",
       "      <td>31.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147745</td>\n",
       "      <td>1</td>\n",
       "      <td>15.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289514</td>\n",
       "      <td>1</td>\n",
       "      <td>29.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289514</td>\n",
       "      <td>2</td>\n",
       "      <td>23.218750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  turn  vificlip_score\n",
       "0  360871     1       25.031250\n",
       "1  360871     2       31.453125\n",
       "2  147745     1       15.851562\n",
       "3  289514     1       29.015625\n",
       "4  289514     2       23.218750"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71370cdc-1e9b-4969-83a4-b1e0c2120a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init new columns\n",
    "dev[\"semantic_category\"] = \"\"\n",
    "dev[\"instruction_type\"] = \"\"\n",
    "dev[\"visual_impact\"] = \"\"\n",
    "dev[\"object_type\"] = \"\"\n",
    "\n",
    "path = \"/home/jovyan/BA/Github/MagicBrush/vifi_format/videos\"\n",
    "\n",
    "for index, row in dev.iterrows():\n",
    "    current_id = int(row[\"id\"])\n",
    "    current_turn = int(row[\"turn\"])\n",
    "\n",
    "    for entry in turns:\n",
    "        output = entry[\"output\"]\n",
    "        match = re.search(pattern, output)\n",
    "\n",
    "        if match:\n",
    "            found_id = int(match.group(1))  # get id of sample\n",
    "            found_turn = int(match.group(2))  # get turn of sample\n",
    "\n",
    "            if found_id == current_id and found_turn == current_turn:\n",
    "                instruction = entry[\"instruction\"].lower()\n",
    "\n",
    "                video_path = os.path.join(path, f\"{found_id}_{found_turn}.mp4\")\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "                ret1, frame1 = cap.read()\n",
    "                ret2, frame2 = cap.read()\n",
    "                cap.release()\n",
    "\n",
    "                if not (ret1 and ret2 and frame1 is not None and frame2 is not None):\n",
    "                    print(f\"Skipping {video_path} due to insufficient frames.\")\n",
    "                    break\n",
    "\n",
    "                frame1 = Image.fromarray(cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB))\n",
    "                frame2 = Image.fromarray(cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "                input_image_encoded = encode_image(frame1)\n",
    "                output_image_encoded = encode_image(frame2)\n",
    "\n",
    "                response = call_api(\n",
    "                    input_image_encoded, output_image_encoded, instruction\n",
    "                )\n",
    "                response = ast.literal_eval(response)\n",
    "\n",
    "                dev.at[index, \"semantic_category\"] = response[0]\n",
    "                dev.at[index, \"instruction_type\"] = response[1]\n",
    "                dev.at[index, \"visual_impact\"] = response[2]\n",
    "                dev.at[index, \"object_type\"] = response[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "103681eb-0d18-4463-9b24-05c211c739af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.drop(columns=[\"vificlip_score\"])\n",
    "dev.to_csv(\"categories.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotation",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
