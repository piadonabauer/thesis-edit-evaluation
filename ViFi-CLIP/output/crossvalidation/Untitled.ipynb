{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5773a87-9011-4db8-9cd7-335c9fef33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.stats.multitest as smm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f7b85f-0eb0-4893-9de8-caa7ca0495ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(folder, mean=True):\n",
    "    json_files = ['fold1/history.json', 'fold2/history.json', \n",
    "                  'fold3/history.json', 'fold4/history.json', 'fold5/history.json']\n",
    "\n",
    "    metrics = ['loss', 'mean_rank', 'median_rank', 'recall@1', 'recall@5', 'recall@10', 'recall@50']\n",
    "    categories = ['Training', 'Validation']\n",
    "\n",
    "    # Initialisiere Dict f√ºr die letzten Werte\n",
    "    last_values = {cat: {m: [] for m in metrics} for cat in categories}\n",
    "\n",
    "    for json_file in json_files:\n",
    "        with open(f\"{folder}/{json_file}\", 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for cat in categories:\n",
    "                for metric in metrics:\n",
    "                    last_values[cat][metric].append(data[cat][metric][-1])\n",
    "\n",
    "    if mean:\n",
    "        # Mittelwerte berechnen\n",
    "        result = {cat: {metric: np.mean(values) for metric, values in metrics.items()} for cat, metrics in last_values.items()}\n",
    "    else:\n",
    "        # Rohwerte beibehalten\n",
    "        result = last_values\n",
    "\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8e6bae-37df-4c04-ac68-47e9b6fff767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>8.388089</td>\n",
       "      <td>8.392132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_rank</th>\n",
       "      <td>140.340878</td>\n",
       "      <td>161.218044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_rank</th>\n",
       "      <td>21.600000</td>\n",
       "      <td>29.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@1</th>\n",
       "      <td>11.554054</td>\n",
       "      <td>9.190556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@5</th>\n",
       "      <td>28.720439</td>\n",
       "      <td>24.131535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@10</th>\n",
       "      <td>38.382601</td>\n",
       "      <td>33.423272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@50</th>\n",
       "      <td>63.754223</td>\n",
       "      <td>59.494098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Training  Validation\n",
       "loss           8.388089    8.392132\n",
       "mean_rank    140.340878  161.218044\n",
       "median_rank   21.600000   29.600000\n",
       "recall@1      11.554054    9.190556\n",
       "recall@5      28.720439   24.131535\n",
       "recall@10     38.382601   33.423272\n",
       "recall@50     63.754223   59.494098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df(\"vitb16_2_humanedit_freeze_none\", mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d34d9a8-7085-4b43-8b8c-90cb7478c0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>9.129075</td>\n",
       "      <td>9.130819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_rank</th>\n",
       "      <td>355.468693</td>\n",
       "      <td>369.143928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_rank</th>\n",
       "      <td>60.200000</td>\n",
       "      <td>77.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@1</th>\n",
       "      <td>8.017045</td>\n",
       "      <td>6.258461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@5</th>\n",
       "      <td>18.710227</td>\n",
       "      <td>15.197954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@10</th>\n",
       "      <td>25.196023</td>\n",
       "      <td>21.388350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@50</th>\n",
       "      <td>47.102273</td>\n",
       "      <td>42.537922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Training  Validation\n",
       "loss           9.129075    9.130819\n",
       "mean_rank    355.468693  369.143928\n",
       "median_rank   60.200000   77.800000\n",
       "recall@1       8.017045    6.258461\n",
       "recall@5      18.710227   15.197954\n",
       "recall@10     25.196023   21.388350\n",
       "recall@50     47.102273   42.537922"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df(\"vitb16_2_magicbrush_freeze_none\", mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a26c25e5-1288-4758-92cc-60f8bb955294",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitb16_2_humanedit = get_df(\"vitb16_2_humanedit_freeze_none\", mean=False)\n",
    "vitb16_2_magicbrush = get_df(\"vitb16_2_magicbrush_freeze_none\", mean=False)\n",
    "vitb16_8_humanedit = get_df(\"vitb16_8_humanedit_freeze_none\", mean=False)\n",
    "vitb32_2_humanedit = get_df(\"vitb32_2_humanedit_freeze_none\", mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "170c21ae-00ba-4ba9-bc34-b1f42c85ca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>[8.387917141656619, 8.387737731675845, 8.38714...</td>\n",
       "      <td>[8.39388031822835, 8.394403858892431, 8.393683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_rank</th>\n",
       "      <td>[138.0785472972973, 141.31186655405406, 141.15...</td>\n",
       "      <td>[165.67622259696458, 152.83558178752108, 162.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_rank</th>\n",
       "      <td>[22, 22, 21, 21, 22]</td>\n",
       "      <td>[33, 28, 32, 28, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@1</th>\n",
       "      <td>[11.465371621621621, 11.84543918918919, 11.634...</td>\n",
       "      <td>[8.347386172006747, 8.263069139966273, 9.44350...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@5</th>\n",
       "      <td>[28.631756756756754, 29.43412162162162, 28.821...</td>\n",
       "      <td>[24.283305227655987, 22.17537942664418, 23.693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@10</th>\n",
       "      <td>[38.09121621621622, 38.38682432432432, 38.7246...</td>\n",
       "      <td>[33.473861720067454, 31.703204047217536, 33.22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@50</th>\n",
       "      <td>[63.914695945945944, 63.36570945945946, 63.893...</td>\n",
       "      <td>[57.67284991568297, 59.86509274873525, 58.4317...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Training  \\\n",
       "loss         [8.387917141656619, 8.387737731675845, 8.38714...   \n",
       "mean_rank    [138.0785472972973, 141.31186655405406, 141.15...   \n",
       "median_rank                               [22, 22, 21, 21, 22]   \n",
       "recall@1     [11.465371621621621, 11.84543918918919, 11.634...   \n",
       "recall@5     [28.631756756756754, 29.43412162162162, 28.821...   \n",
       "recall@10    [38.09121621621622, 38.38682432432432, 38.7246...   \n",
       "recall@50    [63.914695945945944, 63.36570945945946, 63.893...   \n",
       "\n",
       "                                                    Validation  \n",
       "loss         [8.39388031822835, 8.394403858892431, 8.393683...  \n",
       "mean_rank    [165.67622259696458, 152.83558178752108, 162.2...  \n",
       "median_rank                               [33, 28, 32, 28, 27]  \n",
       "recall@1     [8.347386172006747, 8.263069139966273, 9.44350...  \n",
       "recall@5     [24.283305227655987, 22.17537942664418, 23.693...  \n",
       "recall@10    [33.473861720067454, 31.703204047217536, 33.22...  \n",
       "recall@50    [57.67284991568297, 59.86509274873525, 58.4317...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitb16_2_humanedit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6e43d89-aed0-459e-a660-c087dd04c344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vergleich: vitb16_2_humanedit vs vitb16_2_magicbrush ===\n",
      "\n",
      "Validation:\n",
      "loss: t=-627.805, p=0.00000, p-corrected=0.00000\n",
      "mean_rank: t=-26.204, p=0.00000, p-corrected=0.00000\n",
      "median_rank: t=-24.407, p=0.00000, p-corrected=0.00000\n",
      "recall@1: t=6.790, p=0.00103, p-corrected=0.01445\n",
      "recall@5: t=13.269, p=0.00001, p-corrected=0.00008\n",
      "recall@10: t=17.594, p=0.00000, p-corrected=0.00000\n",
      "recall@50: t=17.871, p=0.00000, p-corrected=0.00004\n",
      "\n",
      "=== Vergleich: vitb16_2_humanedit vs vitb16_8_humanedit ===\n",
      "\n",
      "Validation:\n",
      "loss: t=6.025, p=0.00032, p-corrected=0.00484\n",
      "mean_rank: t=2.461, p=0.03945, p-corrected=0.18860\n",
      "median_rank: t=3.862, p=0.00483, p-corrected=0.05790\n",
      "recall@1: t=-1.541, p=0.16208, p-corrected=0.18860\n",
      "recall@5: t=-3.034, p=0.01632, p-corrected=0.13204\n",
      "recall@10: t=-3.432, p=0.01320, p-corrected=0.13204\n",
      "recall@50: t=-2.494, p=0.03772, p-corrected=0.18860\n",
      "\n",
      "=== Vergleich: vitb16_2_humanedit vs vitb32_2_humanedit ===\n",
      "\n",
      "Validation:\n",
      "loss: t=-2.905, p=0.02060, p-corrected=0.13204\n",
      "mean_rank: t=-4.610, p=0.00223, p-corrected=0.02894\n",
      "median_rank: t=-3.481, p=0.01071, p-corrected=0.11782\n",
      "recall@1: t=2.365, p=0.05295, p-corrected=0.18860\n",
      "recall@5: t=2.460, p=0.03992, p-corrected=0.18860\n",
      "recall@10: t=3.326, p=0.01390, p-corrected=0.13204\n",
      "recall@50: t=3.155, p=0.01364, p-corrected=0.13204\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.stats.multitest as smm\n",
    "\n",
    "# Liste der Vergleichs-Datenframes\n",
    "comparisons = {\n",
    "    \"vitb16_2_magicbrush\": vitb16_2_magicbrush,\n",
    "    \"vitb16_8_humanedit\": vitb16_8_humanedit,\n",
    "    \"vitb32_2_humanedit\": vitb32_2_humanedit,\n",
    "}\n",
    "\n",
    "# Ergebnisse speichern\n",
    "results = {}\n",
    "p_values = []\n",
    "\n",
    "# Berechnung der T-Tests und p-Werte nur f√ºr \"Validation\"\n",
    "for name, df in comparisons.items():\n",
    "    results[name] = {}\n",
    "    results[name][\"Validation\"] = {}\n",
    "    for metric in vitb16_2_humanedit[\"Validation\"].keys():\n",
    "        t_stat, p_value = ttest_ind(vitb16_2_humanedit[\"Validation\"][metric], df[\"Validation\"][metric], equal_var=False)\n",
    "        results[name][\"Validation\"][metric] = {\"t-stat\": t_stat, \"p-value\": p_value}\n",
    "        p_values.append(p_value)\n",
    "\n",
    "# Wende die Holm-Korrektur auf alle p-Werte an\n",
    "rejected, pvals_corrected, _, _ = smm.multipletests(p_values, method='holm')\n",
    "\n",
    "# Ausgabe der Ergebnisse mit korrigierten p-Werten\n",
    "p_value_idx = 0  # Um den Index der p-Werte zu verfolgen\n",
    "\n",
    "for name, categories in results.items():\n",
    "    print(f\"\\n=== Vergleich: vitb16_2_humanedit vs {name} ===\")\n",
    "    for category, metrics in categories.items():\n",
    "        if category == \"Validation\":  # Nur \"Validation\" ausgeben\n",
    "            print(f\"\\n{category}:\")\n",
    "            for metric, values in metrics.items():\n",
    "                # Holen des originalen und korrigierten p-Werts\n",
    "                original_p_value = values['p-value']\n",
    "                corrected_p_value = pvals_corrected[p_value_idx]\n",
    "                \n",
    "                # Ergebnisse ausgeben\n",
    "                print(f\"{metric}: t={values['t-stat']:.3f}, p={original_p_value:.5f}, p-corrected={corrected_p_value:.5f}\")\n",
    "                \n",
    "                # Inkrementiere den Index f√ºr die p-Werte\n",
    "                p_value_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1288b6a3-92f7-4034-ba42-368e9921cf78",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fold1/history.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m12\u001b[39m)  \u001b[38;5;66;03m# Assuming there are 11 epochs in each dataset\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m json_file \u001b[38;5;129;01min\u001b[39;00m json_files:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Collect validation data\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fold1/history.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "json_files = ['fold1/history.json', 'fold2/history.json', 'fold3/history.json', 'fold4/history.json', 'fold5/history.json']\n",
    "# List to store the validation data for plotting\n",
    "validation_data = {'recall@1': [], 'recall@5': [], 'recall@10': [], 'recall@50': [],\n",
    "                   'mean_rank': [], 'median_rank': []}\n",
    "\n",
    "# Read each JSON file and collect the values for plotting\n",
    "epochs = range(1, 12)  # Assuming there are 11 epochs in each dataset\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # Collect validation data\n",
    "        validation_data['recall@1'].append(data['Validation']['recall@1'])\n",
    "        validation_data['recall@5'].append(data['Validation']['recall@5'])\n",
    "        validation_data['recall@10'].append(data['Validation']['recall@10'])\n",
    "        validation_data['recall@50'].append(data['Validation']['recall@50'])\n",
    "        validation_data['mean_rank'].append(data['Validation']['mean_rank'])\n",
    "        validation_data['median_rank'].append(data['Validation']['median_rank'])\n",
    "\n",
    "# Convert lists to numpy arrays for easier manipulation\n",
    "validation_data = {key: np.array(value) for key, value in validation_data.items()}\n",
    "\n",
    "# Plotting Recall Curves for Validation\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6))  # 1 row, 2 columns\n",
    "\n",
    "# Recall Curves\n",
    "ax[0].plot(epochs, np.mean(validation_data['recall@1'], axis=0), label='Recall@1', color='green', marker='o')\n",
    "ax[0].plot(epochs, np.mean(validation_data['recall@5'], axis=0), label='Recall@5', color='blue', marker='o')\n",
    "ax[0].plot(epochs, np.mean(validation_data['recall@10'], axis=0), label='Recall@10', color='orange', marker='o')\n",
    "ax[0].plot(epochs, np.mean(validation_data['recall@50'], axis=0), label='Recall@50', color='red', marker='o')\n",
    "ax[0].set_title('Recall@k (Validation Split)', fontsize=18)\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Recall', fontsize=16)\n",
    "ax[0].set_ylim(0, 100)  # Set y-axis limit for recall to range from 0 to 100\n",
    "ax[0].tick_params(axis='both', labelsize=14)  # Increase tick font size\n",
    "ax[0].legend(fontsize=15)\n",
    "\n",
    "# Plotting Mean Rank and Median Rank Curves for Validation\n",
    "ax[1].plot(epochs, np.mean(validation_data['mean_rank'], axis=0), label='Mean Rank', color='purple', marker='o')\n",
    "ax[1].plot(epochs, np.mean(validation_data['median_rank'], axis=0), label='Median Rank', color='brown', marker='o')\n",
    "ax[1].set_title('Mean Rank and Median Rank (Validation Split)', fontsize=18)\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Rank', fontsize=16)\n",
    "ax[1].set_ylim(0, max(np.mean(validation_data['mean_rank'], axis=0)) + 10)  # Ensure y-axis starts from 0 for rank\n",
    "ax[1].tick_params(axis='both', labelsize=14)  # Increase tick font size\n",
    "ax[1].legend(fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"recall_rank_curves.png\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc59bf10-c771-4a16-9b58-30d7d8c05b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c9e7a-41de-4152-8837-3cb32fd47828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91afb72-db8f-4493-a7f2-5cd7e269a832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annotation",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
