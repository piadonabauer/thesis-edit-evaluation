[2025-01-05 13:36:14 ViT-B/32] (main.py 442): INFO working dir: output/base2novel/humanedit/vitb32_2_80_20
[2025-01-05 13:36:14 ViT-B/32] (main.py 446): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  DATASET: humanedit
  INPUT_SIZE: 224
  LABEL_LIST: /home/jovyan/BA/Github/HumanEdit/labels.csv
  NUM_CLASSES: 4534
  NUM_FRAMES: 2
  ROOT: /home/jovyan/BA/Github/HumanEdit/videos
  TRAIN_FILE: /home/jovyan/BA/Github/HumanEdit/train_80.txt
  VAL_FILE: /home/jovyan/BA/Github/HumanEdit/test_20.txt
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/32
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  PRETRAINED: None
  RESUME: None
OUTPUT: output/base2novel/humanedit/vitb32_2_80_20
PRINT_FREQ: 50
SAVE_FREQ: 10
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: False
  BATCH_SIZE: 32
  EPOCHS: 11
  LR: 2e-06
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 5
  WEIGHT_DECAY: 0.001
TRAINER:
  ViFi_CLIP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
VAL_FREQ: 1
[2025-01-05 13:36:14 ViT-B/32] (vificlip.py 217): INFO Loading CLIP (backbone: ViT-B/32)
[2025-01-05 13:36:16 ViT-B/32] (vificlip.py 220): INFO Building ViFi-CLIP CLIP
[2025-01-05 13:36:16 ViT-B/32] (vificlip.py 237): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-01-05 13:36:16 ViT-B/32] (vificlip.py 261): INFO Total learnable items: 301
[2025-01-05 13:36:22 ViT-B/32] (main.py 193): INFO Train: [0/11][0/150]	eta 0:12:37 lr 0.000000000	time 5.0480 (5.0480)	tot_loss 4.4341 (4.4341)	mem 3855MB
[2025-01-05 13:36:28 ViT-B/32] (main.py 193): INFO Train: [0/11][50/150]	eta 0:00:20 lr 0.000000131	time 0.0996 (0.2095)	tot_loss 4.0198 (4.0867)	mem 4263MB
[2025-01-05 13:36:34 ViT-B/32] (main.py 193): INFO Train: [0/11][100/150]	eta 0:00:08 lr 0.000000264	time 0.1061 (0.1623)	tot_loss 3.8237 (4.0722)	mem 4263MB
[2025-01-05 13:36:39 ViT-B/32] (main.py 200): INFO EPOCH 0 training takes 0:00:21
[2025-01-05 13:36:39 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:36:47 ViT-B/32] (main.py 388): INFO Training Loss: 8.4013
[2025-01-05 13:36:47 ViT-B/32] (main.py 389): INFO  * Acc@1 5.042 Acc@5 13.208 Acc@10 19.271 Acc@50 39.938
[2025-01-05 13:36:47 ViT-B/32] (main.py 390): INFO  * Macro P: 0.030, R: 0.051, F1: 0.034
[2025-01-05 13:36:47 ViT-B/32] (main.py 391): INFO  * Micro P: 0.050, R: 0.050, F1: 0.050
[2025-01-05 13:36:47 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:36:54 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3968
[2025-01-05 13:36:54 ViT-B/32] (main.py 389): INFO  * Acc@1 6.206 Acc@5 16.489 Acc@10 23.138 Acc@50 43.972
[2025-01-05 13:36:54 ViT-B/32] (main.py 390): INFO  * Macro P: 0.014, R: 0.015, F1: 0.014
[2025-01-05 13:36:54 ViT-B/32] (main.py 391): INFO  * Micro P: 0.062, R: 0.062, F1: 0.062
[2025-01-05 13:36:54 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 6.2%
[2025-01-05 13:36:54 ViT-B/32] (main.py 116): INFO Max accuracy: 6.21%
[2025-01-05 13:36:54 ViT-B/32] (tools.py 55): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_0.pth saving......
[2025-01-05 13:37:11 ViT-B/32] (tools.py 57): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_0.pth saved !!!
[2025-01-05 13:37:30 ViT-B/32] (tools.py 61): INFO output/base2novel/humanedit/vitb32_2_80_20/best.pth saved !!!
[2025-01-05 13:37:31 ViT-B/32] (main.py 193): INFO Train: [1/11][0/150]	eta 0:02:52 lr 0.000000397	time 1.1521 (1.1521)	tot_loss 4.0348 (4.0348)	mem 4263MB
[2025-01-05 13:37:36 ViT-B/32] (main.py 193): INFO Train: [1/11][50/150]	eta 0:00:13 lr 0.000000531	time 0.1049 (0.1352)	tot_loss 3.7583 (3.8452)	mem 4265MB
[2025-01-05 13:37:42 ViT-B/32] (main.py 193): INFO Train: [1/11][100/150]	eta 0:00:06 lr 0.000000664	time 0.1090 (0.1251)	tot_loss 3.8862 (3.8156)	mem 4265MB
[2025-01-05 13:37:48 ViT-B/32] (main.py 200): INFO EPOCH 1 training takes 0:00:18
[2025-01-05 13:37:48 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:37:56 ViT-B/32] (main.py 388): INFO Training Loss: 8.4053
[2025-01-05 13:37:56 ViT-B/32] (main.py 389): INFO  * Acc@1 5.229 Acc@5 14.667 Acc@10 22.062 Acc@50 43.229
[2025-01-05 13:37:56 ViT-B/32] (main.py 390): INFO  * Macro P: 0.029, R: 0.052, F1: 0.034
[2025-01-05 13:37:56 ViT-B/32] (main.py 391): INFO  * Micro P: 0.052, R: 0.052, F1: 0.052
[2025-01-05 13:37:56 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:38:03 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3994
[2025-01-05 13:38:03 ViT-B/32] (main.py 389): INFO  * Acc@1 7.181 Acc@5 18.174 Acc@10 25.000 Acc@50 44.947
[2025-01-05 13:38:03 ViT-B/32] (main.py 390): INFO  * Macro P: 0.015, R: 0.017, F1: 0.016
[2025-01-05 13:38:03 ViT-B/32] (main.py 391): INFO  * Micro P: 0.072, R: 0.072, F1: 0.072
[2025-01-05 13:38:03 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.2%
[2025-01-05 13:38:03 ViT-B/32] (main.py 116): INFO Max accuracy: 7.18%
[2025-01-05 13:38:03 ViT-B/32] (tools.py 55): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_1.pth saving......
[2025-01-05 13:38:21 ViT-B/32] (tools.py 57): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_1.pth saved !!!
[2025-01-05 13:38:40 ViT-B/32] (tools.py 61): INFO output/base2novel/humanedit/vitb32_2_80_20/best.pth saved !!!
[2025-01-05 13:38:41 ViT-B/32] (main.py 193): INFO Train: [2/11][0/150]	eta 0:03:24 lr 0.000000797	time 1.3664 (1.3664)	tot_loss 3.7852 (3.7852)	mem 4265MB
[2025-01-05 13:38:47 ViT-B/32] (main.py 193): INFO Train: [2/11][50/150]	eta 0:00:13 lr 0.000000931	time 0.1015 (0.1395)	tot_loss 3.1294 (3.6230)	mem 4265MB
[2025-01-05 13:38:52 ViT-B/32] (main.py 193): INFO Train: [2/11][100/150]	eta 0:00:06 lr 0.000001064	time 0.1029 (0.1273)	tot_loss 3.7809 (3.6623)	mem 4265MB
[2025-01-05 13:38:58 ViT-B/32] (main.py 200): INFO EPOCH 2 training takes 0:00:18
[2025-01-05 13:38:58 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:39:06 ViT-B/32] (main.py 388): INFO Training Loss: 8.4056
[2025-01-05 13:39:06 ViT-B/32] (main.py 389): INFO  * Acc@1 6.229 Acc@5 17.188 Acc@10 24.729 Acc@50 47.396
[2025-01-05 13:39:06 ViT-B/32] (main.py 390): INFO  * Macro P: 0.033, R: 0.061, F1: 0.039
[2025-01-05 13:39:06 ViT-B/32] (main.py 391): INFO  * Micro P: 0.062, R: 0.062, F1: 0.062
[2025-01-05 13:39:06 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:39:13 ViT-B/32] (main.py 388): INFO Validation Loss: 8.4002
[2025-01-05 13:39:13 ViT-B/32] (main.py 389): INFO  * Acc@1 7.358 Acc@5 19.415 Acc@10 26.596 Acc@50 47.163
[2025-01-05 13:39:13 ViT-B/32] (main.py 390): INFO  * Macro P: 0.015, R: 0.018, F1: 0.016
[2025-01-05 13:39:13 ViT-B/32] (main.py 391): INFO  * Micro P: 0.074, R: 0.074, F1: 0.074
[2025-01-05 13:39:13 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.4%
[2025-01-05 13:39:13 ViT-B/32] (main.py 116): INFO Max accuracy: 7.36%
[2025-01-05 13:39:13 ViT-B/32] (tools.py 55): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_2.pth saving......
[2025-01-05 13:39:32 ViT-B/32] (tools.py 57): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_2.pth saved !!!
[2025-01-05 13:39:50 ViT-B/32] (tools.py 61): INFO output/base2novel/humanedit/vitb32_2_80_20/best.pth saved !!!
[2025-01-05 13:39:51 ViT-B/32] (main.py 193): INFO Train: [3/11][0/150]	eta 0:03:08 lr 0.000001197	time 1.2558 (1.2558)	tot_loss 3.6300 (3.6300)	mem 4265MB
[2025-01-05 13:39:57 ViT-B/32] (main.py 193): INFO Train: [3/11][50/150]	eta 0:00:13 lr 0.000001331	time 0.1053 (0.1367)	tot_loss 3.5575 (3.5670)	mem 4265MB
[2025-01-05 13:40:02 ViT-B/32] (main.py 193): INFO Train: [3/11][100/150]	eta 0:00:06 lr 0.000001464	time 0.1012 (0.1254)	tot_loss 3.7123 (3.5830)	mem 4265MB
[2025-01-05 13:40:08 ViT-B/32] (main.py 200): INFO EPOCH 3 training takes 0:00:18
[2025-01-05 13:40:08 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:40:16 ViT-B/32] (main.py 388): INFO Training Loss: 8.4046
[2025-01-05 13:40:16 ViT-B/32] (main.py 389): INFO  * Acc@1 6.833 Acc@5 18.396 Acc@10 26.062 Acc@50 49.917
[2025-01-05 13:40:16 ViT-B/32] (main.py 390): INFO  * Macro P: 0.035, R: 0.065, F1: 0.041
[2025-01-05 13:40:16 ViT-B/32] (main.py 391): INFO  * Micro P: 0.068, R: 0.068, F1: 0.068
[2025-01-05 13:40:16 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:40:24 ViT-B/32] (main.py 388): INFO Validation Loss: 8.4008
[2025-01-05 13:40:24 ViT-B/32] (main.py 389): INFO  * Acc@1 8.067 Acc@5 19.060 Acc@10 28.014 Acc@50 47.784
[2025-01-05 13:40:24 ViT-B/32] (main.py 390): INFO  * Macro P: 0.016, R: 0.019, F1: 0.017
[2025-01-05 13:40:24 ViT-B/32] (main.py 391): INFO  * Micro P: 0.081, R: 0.081, F1: 0.081
[2025-01-05 13:40:24 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 8.1%
[2025-01-05 13:40:24 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:40:24 ViT-B/32] (tools.py 55): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_3.pth saving......
[2025-01-05 13:40:41 ViT-B/32] (tools.py 57): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_3.pth saved !!!
[2025-01-05 13:40:59 ViT-B/32] (tools.py 61): INFO output/base2novel/humanedit/vitb32_2_80_20/best.pth saved !!!
[2025-01-05 13:41:01 ViT-B/32] (main.py 193): INFO Train: [4/11][0/150]	eta 0:02:51 lr 0.000001597	time 1.1435 (1.1435)	tot_loss 3.4981 (3.4981)	mem 4265MB
[2025-01-05 13:41:06 ViT-B/32] (main.py 193): INFO Train: [4/11][50/150]	eta 0:00:13 lr 0.000001731	time 0.1016 (0.1356)	tot_loss 3.5487 (3.5902)	mem 4265MB
[2025-01-05 13:41:12 ViT-B/32] (main.py 193): INFO Train: [4/11][100/150]	eta 0:00:06 lr 0.000001864	time 0.1014 (0.1252)	tot_loss 3.6634 (3.5764)	mem 4265MB
[2025-01-05 13:41:18 ViT-B/32] (main.py 200): INFO EPOCH 4 training takes 0:00:18
[2025-01-05 13:41:18 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:41:26 ViT-B/32] (main.py 388): INFO Training Loss: 8.4020
[2025-01-05 13:41:26 ViT-B/32] (main.py 389): INFO  * Acc@1 7.979 Acc@5 20.875 Acc@10 28.875 Acc@50 52.479
[2025-01-05 13:41:26 ViT-B/32] (main.py 390): INFO  * Macro P: 0.041, R: 0.075, F1: 0.048
[2025-01-05 13:41:26 ViT-B/32] (main.py 391): INFO  * Micro P: 0.080, R: 0.080, F1: 0.080
[2025-01-05 13:41:26 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:41:33 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3993
[2025-01-05 13:41:33 ViT-B/32] (main.py 389): INFO  * Acc@1 7.004 Acc@5 20.567 Acc@10 28.546 Acc@50 50.975
[2025-01-05 13:41:33 ViT-B/32] (main.py 390): INFO  * Macro P: 0.014, R: 0.017, F1: 0.015
[2025-01-05 13:41:33 ViT-B/32] (main.py 391): INFO  * Micro P: 0.070, R: 0.070, F1: 0.070
[2025-01-05 13:41:33 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.0%
[2025-01-05 13:41:33 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:41:34 ViT-B/32] (main.py 193): INFO Train: [5/11][0/150]	eta 0:02:50 lr 0.000001997	time 1.1341 (1.1341)	tot_loss 3.2737 (3.2737)	mem 4265MB
[2025-01-05 13:41:40 ViT-B/32] (main.py 193): INFO Train: [5/11][50/150]	eta 0:00:13 lr 0.000001059	time 0.1067 (0.1348)	tot_loss 3.6576 (3.4542)	mem 4265MB
[2025-01-05 13:41:46 ViT-B/32] (main.py 193): INFO Train: [5/11][100/150]	eta 0:00:06 lr 0.000000965	time 0.1019 (0.1254)	tot_loss 3.6096 (3.4874)	mem 4265MB
[2025-01-05 13:41:52 ViT-B/32] (main.py 200): INFO EPOCH 5 training takes 0:00:18
[2025-01-05 13:41:52 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:42:00 ViT-B/32] (main.py 388): INFO Training Loss: 8.4011
[2025-01-05 13:42:00 ViT-B/32] (main.py 389): INFO  * Acc@1 7.833 Acc@5 21.188 Acc@10 30.000 Acc@50 54.333
[2025-01-05 13:42:00 ViT-B/32] (main.py 390): INFO  * Macro P: 0.041, R: 0.074, F1: 0.048
[2025-01-05 13:42:00 ViT-B/32] (main.py 391): INFO  * Micro P: 0.078, R: 0.078, F1: 0.078
[2025-01-05 13:42:00 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:42:07 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3988
[2025-01-05 13:42:07 ViT-B/32] (main.py 389): INFO  * Acc@1 7.270 Acc@5 20.656 Acc@10 29.344 Acc@50 51.152
[2025-01-05 13:42:07 ViT-B/32] (main.py 390): INFO  * Macro P: 0.014, R: 0.017, F1: 0.015
[2025-01-05 13:42:07 ViT-B/32] (main.py 391): INFO  * Micro P: 0.073, R: 0.073, F1: 0.073
[2025-01-05 13:42:07 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.3%
[2025-01-05 13:42:07 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:42:08 ViT-B/32] (main.py 193): INFO Train: [6/11][0/150]	eta 0:02:48 lr 0.000000871	time 1.1201 (1.1201)	tot_loss 3.5232 (3.5232)	mem 4265MB
[2025-01-05 13:42:14 ViT-B/32] (main.py 193): INFO Train: [6/11][50/150]	eta 0:00:13 lr 0.000000778	time 0.1037 (0.1367)	tot_loss 3.8586 (3.3974)	mem 4265MB
[2025-01-05 13:42:20 ViT-B/32] (main.py 193): INFO Train: [6/11][100/150]	eta 0:00:06 lr 0.000000688	time 0.1067 (0.1264)	tot_loss 3.3859 (3.4516)	mem 4265MB
[2025-01-05 13:42:26 ViT-B/32] (main.py 200): INFO EPOCH 6 training takes 0:00:18
[2025-01-05 13:42:26 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:42:34 ViT-B/32] (main.py 388): INFO Training Loss: 8.4000
[2025-01-05 13:42:34 ViT-B/32] (main.py 389): INFO  * Acc@1 8.083 Acc@5 21.958 Acc@10 31.104 Acc@50 55.708
[2025-01-05 13:42:34 ViT-B/32] (main.py 390): INFO  * Macro P: 0.041, R: 0.075, F1: 0.048
[2025-01-05 13:42:34 ViT-B/32] (main.py 391): INFO  * Micro P: 0.081, R: 0.081, F1: 0.081
[2025-01-05 13:42:34 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:42:41 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3983
[2025-01-05 13:42:41 ViT-B/32] (main.py 389): INFO  * Acc@1 7.624 Acc@5 20.656 Acc@10 29.876 Acc@50 51.862
[2025-01-05 13:42:41 ViT-B/32] (main.py 390): INFO  * Macro P: 0.015, R: 0.018, F1: 0.016
[2025-01-05 13:42:41 ViT-B/32] (main.py 391): INFO  * Micro P: 0.076, R: 0.076, F1: 0.076
[2025-01-05 13:42:41 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.6%
[2025-01-05 13:42:41 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:42:42 ViT-B/32] (main.py 193): INFO Train: [7/11][0/150]	eta 0:02:53 lr 0.000000600	time 1.1547 (1.1547)	tot_loss 3.5713 (3.5713)	mem 4265MB
[2025-01-05 13:42:48 ViT-B/32] (main.py 193): INFO Train: [7/11][50/150]	eta 0:00:13 lr 0.000000517	time 0.1014 (0.1363)	tot_loss 3.1094 (3.4726)	mem 4265MB
[2025-01-05 13:42:54 ViT-B/32] (main.py 193): INFO Train: [7/11][100/150]	eta 0:00:06 lr 0.000000437	time 0.1057 (0.1265)	tot_loss 3.6708 (3.4813)	mem 4265MB
[2025-01-05 13:43:00 ViT-B/32] (main.py 200): INFO EPOCH 7 training takes 0:00:18
[2025-01-05 13:43:00 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:43:08 ViT-B/32] (main.py 388): INFO Training Loss: 8.3992
[2025-01-05 13:43:08 ViT-B/32] (main.py 389): INFO  * Acc@1 8.854 Acc@5 22.542 Acc@10 31.188 Acc@50 56.583
[2025-01-05 13:43:08 ViT-B/32] (main.py 390): INFO  * Macro P: 0.045, R: 0.079, F1: 0.052
[2025-01-05 13:43:08 ViT-B/32] (main.py 391): INFO  * Micro P: 0.089, R: 0.089, F1: 0.089
[2025-01-05 13:43:08 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:43:15 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3980
[2025-01-05 13:43:15 ViT-B/32] (main.py 389): INFO  * Acc@1 7.270 Acc@5 20.745 Acc@10 29.699 Acc@50 51.330
[2025-01-05 13:43:15 ViT-B/32] (main.py 390): INFO  * Macro P: 0.014, R: 0.017, F1: 0.015
[2025-01-05 13:43:15 ViT-B/32] (main.py 391): INFO  * Micro P: 0.073, R: 0.073, F1: 0.073
[2025-01-05 13:43:15 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.3%
[2025-01-05 13:43:15 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:43:16 ViT-B/32] (main.py 193): INFO Train: [8/11][0/150]	eta 0:02:48 lr 0.000000363	time 1.1204 (1.1204)	tot_loss 3.7450 (3.7450)	mem 4265MB
[2025-01-05 13:43:22 ViT-B/32] (main.py 193): INFO Train: [8/11][50/150]	eta 0:00:13 lr 0.000000295	time 0.1062 (0.1360)	tot_loss 3.5791 (3.4030)	mem 4265MB
[2025-01-05 13:43:28 ViT-B/32] (main.py 193): INFO Train: [8/11][100/150]	eta 0:00:06 lr 0.000000233	time 0.1028 (0.1257)	tot_loss 3.5714 (3.4128)	mem 4265MB
[2025-01-05 13:43:33 ViT-B/32] (main.py 200): INFO EPOCH 8 training takes 0:00:18
[2025-01-05 13:43:33 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:43:42 ViT-B/32] (main.py 388): INFO Training Loss: 8.3986
[2025-01-05 13:43:42 ViT-B/32] (main.py 389): INFO  * Acc@1 8.771 Acc@5 23.125 Acc@10 31.979 Acc@50 56.021
[2025-01-05 13:43:42 ViT-B/32] (main.py 390): INFO  * Macro P: 0.044, R: 0.081, F1: 0.052
[2025-01-05 13:43:42 ViT-B/32] (main.py 391): INFO  * Micro P: 0.088, R: 0.088, F1: 0.088
[2025-01-05 13:43:42 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:43:49 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3977
[2025-01-05 13:43:49 ViT-B/32] (main.py 389): INFO  * Acc@1 7.181 Acc@5 21.011 Acc@10 29.610 Acc@50 51.330
[2025-01-05 13:43:49 ViT-B/32] (main.py 390): INFO  * Macro P: 0.014, R: 0.017, F1: 0.015
[2025-01-05 13:43:49 ViT-B/32] (main.py 391): INFO  * Micro P: 0.072, R: 0.072, F1: 0.072
[2025-01-05 13:43:49 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.2%
[2025-01-05 13:43:49 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:43:50 ViT-B/32] (main.py 193): INFO Train: [9/11][0/150]	eta 0:03:49 lr 0.000000178	time 1.5313 (1.5313)	tot_loss 3.7423 (3.7423)	mem 4265MB
[2025-01-05 13:43:56 ViT-B/32] (main.py 193): INFO Train: [9/11][50/150]	eta 0:00:14 lr 0.000000131	time 0.1057 (0.1445)	tot_loss 3.4895 (3.4581)	mem 4265MB
[2025-01-05 13:44:02 ViT-B/32] (main.py 193): INFO Train: [9/11][100/150]	eta 0:00:06 lr 0.000000092	time 0.1046 (0.1309)	tot_loss 3.8710 (3.4522)	mem 4265MB
[2025-01-05 13:44:08 ViT-B/32] (main.py 200): INFO EPOCH 9 training takes 0:00:18
[2025-01-05 13:44:08 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:44:16 ViT-B/32] (main.py 388): INFO Training Loss: 8.3990
[2025-01-05 13:44:16 ViT-B/32] (main.py 389): INFO  * Acc@1 8.917 Acc@5 22.729 Acc@10 31.333 Acc@50 56.771
[2025-01-05 13:44:16 ViT-B/32] (main.py 390): INFO  * Macro P: 0.045, R: 0.082, F1: 0.052
[2025-01-05 13:44:16 ViT-B/32] (main.py 391): INFO  * Micro P: 0.089, R: 0.089, F1: 0.089
[2025-01-05 13:44:16 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:44:24 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3979
[2025-01-05 13:44:24 ViT-B/32] (main.py 389): INFO  * Acc@1 7.270 Acc@5 20.833 Acc@10 29.699 Acc@50 51.418
[2025-01-05 13:44:24 ViT-B/32] (main.py 390): INFO  * Macro P: 0.014, R: 0.017, F1: 0.015
[2025-01-05 13:44:24 ViT-B/32] (main.py 391): INFO  * Micro P: 0.073, R: 0.073, F1: 0.073
[2025-01-05 13:44:24 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.3%
[2025-01-05 13:44:24 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:44:25 ViT-B/32] (main.py 193): INFO Train: [10/11][0/150]	eta 0:03:25 lr 0.000000061	time 1.3716 (1.3716)	tot_loss 3.6564 (3.6564)	mem 4265MB
[2025-01-05 13:44:31 ViT-B/32] (main.py 193): INFO Train: [10/11][50/150]	eta 0:00:14 lr 0.000000038	time 0.1032 (0.1418)	tot_loss 3.4814 (3.4586)	mem 4265MB
[2025-01-05 13:44:37 ViT-B/32] (main.py 193): INFO Train: [10/11][100/150]	eta 0:00:06 lr 0.000000025	time 0.1066 (0.1291)	tot_loss 3.4466 (3.4440)	mem 4265MB
[2025-01-05 13:44:43 ViT-B/32] (main.py 200): INFO EPOCH 10 training takes 0:00:18
[2025-01-05 13:44:43 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:44:51 ViT-B/32] (main.py 388): INFO Training Loss: 8.3991
[2025-01-05 13:44:51 ViT-B/32] (main.py 389): INFO  * Acc@1 8.625 Acc@5 23.062 Acc@10 31.021 Acc@50 55.708
[2025-01-05 13:44:51 ViT-B/32] (main.py 390): INFO  * Macro P: 0.043, R: 0.078, F1: 0.050
[2025-01-05 13:44:51 ViT-B/32] (main.py 391): INFO  * Micro P: 0.086, R: 0.086, F1: 0.086
[2025-01-05 13:44:51 ViT-B/32] (main.py 302): INFO 1 views inference
[2025-01-05 13:44:59 ViT-B/32] (main.py 388): INFO Validation Loss: 8.3978
[2025-01-05 13:44:59 ViT-B/32] (main.py 389): INFO  * Acc@1 7.358 Acc@5 20.922 Acc@10 29.610 Acc@50 51.330
[2025-01-05 13:44:59 ViT-B/32] (main.py 390): INFO  * Macro P: 0.015, R: 0.017, F1: 0.015
[2025-01-05 13:44:59 ViT-B/32] (main.py 391): INFO  * Micro P: 0.074, R: 0.074, F1: 0.074
[2025-01-05 13:44:59 ViT-B/32] (main.py 113): INFO Accuracy of the network on the 1128 test videos: 7.4%
[2025-01-05 13:44:59 ViT-B/32] (main.py 116): INFO Max accuracy: 8.07%
[2025-01-05 13:44:59 ViT-B/32] (tools.py 55): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_10.pth saving......
[2025-01-05 13:45:17 ViT-B/32] (tools.py 57): INFO output/base2novel/humanedit/vitb32_2_80_20/ckpt_epoch_10.pth saved !!!
