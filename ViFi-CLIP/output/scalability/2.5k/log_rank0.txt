[2025-03-13 14:28:23 ViT-B/16] (main.py 348): INFO working dir: output/scalability/2.5k
[2025-03-13 14:28:23 ViT-B/16] (main.py 352): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  DATASET: humanedit
  INPUT_SIZE: 224
  LABEL_LIST: /home/jovyan/BA/Github/thesis-edit-evaluation/data/humanedit/labels.csv
  NUM_CLASSES: 4534
  NUM_FRAMES: 2
  ROOT: /home/jovyan/BA/Github/HumanEdit/videos
  TRAIN_FILE: /home/jovyan/BA/Github/HumanEdit/train_2.5k.txt
  VAL_FILE: /home/jovyan/BA/Github/HumanEdit/test_20.txt
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  PRETRAINED: None
  RESUME: None
OUTPUT: output/scalability/2.5k
PRINT_FREQ: 50
SAVE_FREQ: 10
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 2
  AUTO_RESUME: False
  BATCH_SIZE: 16
  EPOCHS: 11
  LR: 2e-06
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 5
  WEIGHT_DECAY: 0.001
TRAINER:
  ViFi_CLIP:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
VAL_FREQ: 1
[2025-03-13 14:28:23 ViT-B/16] (vificlip.py 242): INFO Loading CLIP (backbone: ViT-B/16)
[2025-03-13 14:28:24 ViT-B/16] (vificlip.py 245): INFO Building ViFi-CLIP CLIP
[2025-03-13 14:28:25 ViT-B/16] (vificlip.py 262): INFO Turning on gradients for COMPLETE ViFi-CLIP model
[2025-03-13 14:28:25 ViT-B/16] (vificlip.py 286): INFO Total learnable items: 302
[2025-03-13 14:28:28 ViT-B/16] (main.py 184): INFO Train: [0/11][0/156]	eta 0:08:40 lr 0.000000000	time 3.3386 (3.3386)	tot_loss 4.0588 (4.0588)	mem 6882MB
[2025-03-13 14:30:11 ViT-B/16] (main.py 184): INFO Train: [0/11][50/156]	eta 0:03:39 lr 0.000000126	time 2.1387 (2.0729)	tot_loss 3.9049 (3.9986)	mem 7887MB
[2025-03-13 14:31:58 ViT-B/16] (main.py 184): INFO Train: [0/11][100/156]	eta 0:01:58 lr 0.000000254	time 2.1369 (2.1105)	tot_loss 4.5240 (3.9910)	mem 7887MB
[2025-03-13 14:33:45 ViT-B/16] (main.py 184): INFO Train: [0/11][150/156]	eta 0:00:12 lr 0.000000382	time 2.1369 (2.1227)	tot_loss 3.5101 (3.9613)	mem 7887MB
[2025-03-13 14:33:56 ViT-B/16] (main.py 191): INFO EPOCH 0 training takes 0:05:31
[2025-03-13 14:33:56 ViT-B/16] (main.py 258): INFO 1 views inference
[2025-03-13 14:52:07 ViT-B/16] (main.py 299): INFO Validation
[2025-03-13 14:52:07 ViT-B/16] (main.py 300): INFO  * Loss: 8.3914
[2025-03-13 14:52:07 ViT-B/16] (main.py 301): INFO  * Mean Rank: 273.239, Median Rank: 72.000
[2025-03-13 14:52:07 ViT-B/16] (main.py 302): INFO  * Recall@1: 6.560, Recall@5: 18.528, Recall@10: 25.887, Recall@50: 43.972
[2025-03-13 14:52:07 ViT-B/16] (main.py 111): INFO Accuracy of the network on the 1128 test videos: 6.6%
[2025-03-13 14:52:07 ViT-B/16] (main.py 114): INFO Max accuracy: 6.56%
[2025-03-13 14:52:07 ViT-B/16] (tools.py 55): INFO output/scalability/2.5k/ckpt_epoch_0.pth saving......
[2025-03-13 14:52:25 ViT-B/16] (tools.py 57): INFO output/scalability/2.5k/ckpt_epoch_0.pth saved !!!
[2025-03-13 14:52:44 ViT-B/16] (tools.py 61): INFO output/scalability/2.5k/best.pth saved !!!
